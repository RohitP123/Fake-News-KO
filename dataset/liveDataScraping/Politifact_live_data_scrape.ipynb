{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RScK8mMqEiup",
        "outputId": "367a6149-9e8a-4906-ac58-5eb6ace52071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/981.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.8/981.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=bef4d00a326e8e7f9c129ac61b3b445d43cde46ac29d763ade69f4c851a30eb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the dependencies\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "import urllib.request\n",
        "import time\n",
        "\n",
        "#Create lists to store the scraped data\n",
        "authors = []\n",
        "dates = []\n",
        "statements = []\n",
        "sources = []\n",
        "targets = []\n",
        "raw_targets= []\n",
        "\n",
        "#Create a function to scrape the site\n",
        "def scrape_website(page_number, source):\n",
        "    page_num = str(page_number) #Convert the page number to a string\n",
        "\n",
        "\n",
        "    '''source: all'''\n",
        "    URL = 'https://www.politifact.com/factchecks/list/?page='+page_num #append the page number to complete the URL\n",
        "\n",
        "    webpage = requests.get(URL)  #Make a request to the website\n",
        "    #time.sleep(3)\n",
        "    soup = BeautifulSoup(webpage.text, \"html.parser\") #Parse the text from the website\n",
        "    #Get the tags and it's class\n",
        "    statement_footer =  soup.find_all('footer',attrs={'class':'m-statement__footer'})  #Get the tag and it's class\n",
        "    statement_quote = soup.find_all('div', attrs={'class':'m-statement__quote'}) #Get the tag and it's class\n",
        "    statement_meta = soup.find_all('div', attrs={'class':'m-statement__meta'})#Get the tag and it's class\n",
        "    target = soup.find_all('div', attrs={'class':'m-statement__meter'}) #Get the tag and it's class\n",
        "\n",
        "    #loop through the footer class m-statement__footer to get the date and author\n",
        "    for i in statement_footer:\n",
        "        link1 = i.text.strip()\n",
        "        name_and_date = link1.split()\n",
        "        first_name = name_and_date[1]\n",
        "        last_name = name_and_date[2]\n",
        "        full_name = first_name+' '+last_name\n",
        "        month = name_and_date[4]\n",
        "        day = name_and_date[5]\n",
        "        year = name_and_date[6]\n",
        "        date = month+' '+day+' '+year\n",
        "        dates.append(date)\n",
        "        authors.append(full_name)\n",
        "    for i in statement_quote:\n",
        "        link2 = i.find_all('a')\n",
        "        statement_text = link2[0].text.strip()\n",
        "        try:\n",
        "            if detect(statement_text) == 'en':\n",
        "                statements.append(statement_text)\n",
        "            else:\n",
        "                statements.append(\"not english\")\n",
        "        except:\n",
        "            continue  # Skip if language detection fails\n",
        "    #Loop through the div m-statement__meta to get the source\n",
        "    for i in statement_meta:\n",
        "        link3 = i.find_all('a') #Source\n",
        "        source_text = link3[0].text.strip()\n",
        "        sources.append(source_text)\n",
        "    #Loop through the target or the div m-statement__meter to get the facts about the statement (True or False)\n",
        "    counter = 0\n",
        "    for index, each in enumerate(target):\n",
        "        counter += 1\n",
        "        fact = each.find('div', attrs={'class':'c-image'}).find('img').get('alt')\n",
        "        raw_targets.append(fact)\n",
        "        if 'true' in fact and 'barely-true' not in fact :\n",
        "          targets.append(1)\n",
        "        elif 'flip' in fact or 'flop' in fact or 'not english' in statements[index]:\n",
        "          targets.append(2)\n",
        "        else:\n",
        "          targets.append(0)\n",
        "\n",
        "\n",
        "\n",
        "#Loop through 'n-1' webpages to scrape the data\n",
        "n=100\n",
        "for i in range(1, n):\n",
        "    scrape_website(i, source='')\n",
        "print(len(authors))\n",
        "print(len(dates))\n",
        "print(len(statements))\n",
        "print(len(sources))\n",
        "print(len(targets))\n",
        "#Create a new dataFrame\n",
        "data = pd.DataFrame(columns = ['title',  'label'])\n",
        "# data['author'] = authors\n",
        "data['title'] = statements\n",
        "# data['source'] = sources\n",
        "# data['date'] = dates\n",
        "data['label'] = targets\n",
        "\n",
        "data = data[data['label'] != 2]\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "# data['raw_target'] = raw_targets\n",
        "#Show the data set\n",
        "print(data)\n",
        "print(set(raw_targets))\n",
        "\n",
        "print(data['label'].value_counts())\n",
        "data.to_csv('politifact-sample.csv', index=False, sep=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLya3WQ3QqhN",
        "outputId": "7ade4100-66df-4a02-af89-2b38ecb535d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2970\n",
            "2970\n",
            "2970\n",
            "2970\n",
            "2970\n",
            "                                                  title  label\n",
            "0     Arizona Democrats “needed a lawsuit to force t...      0\n",
            "1     Former U.S. Rep. Liz Cheney wrote a viral lett...      0\n",
            "2     Under the SAVE Act, “as long as you have a Rea...      0\n",
            "3     “Less than half of Americans have $1,000 in sa...      0\n",
            "4     Cody Balmer, the person charged with setting f...      0\n",
            "...                                                 ...    ...\n",
            "2772  Roseanne Barr made a video of a rainbow in a s...      0\n",
            "2773         “Arizona BANS Electronic Voting Machines.”      0\n",
            "2774                                        not english      0\n",
            "2775  “Miami-Dade County has banned” Amanda Gorman’s...      0\n",
            "2776  A chart on Arctic sea ice provides evidence th...      1\n",
            "\n",
            "[2777 rows x 2 columns]\n",
            "{'false', 'half-flip', 'half-true', 'true', 'pants-fire', 'mostly-true', 'barely-true', 'full-flop'}\n",
            "label\n",
            "0    2512\n",
            "1     265\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}