{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6CETAfA9TUJ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6_dZKquhivo",
        "outputId": "83c7a611-cd2d-4fb4-c351-e84bcdd11b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching fact checks for query: politics\n",
            "Fetching fact checks for query: election\n",
            "Fetching fact checks for query: economy\n",
            "Fetching fact checks for query: climate\n",
            "Fetching fact checks for query: health\n",
            "Fetching fact checks for query: immigration\n",
            "Fetching fact checks for query: war\n",
            "Fetching fact checks for query: military\n",
            "Fetching fact checks for query: technology\n",
            "Fetching fact checks for query: social media\n",
            "Error fetching data: 400\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": 400,\n",
            "    \"message\": \"Invalid request, must have either query or filter.\",\n",
            "    \"status\": \"INVALID_ARGUMENT\"\n",
            "  }\n",
            "}\n",
            "\n",
            "Dataset created with 92 entries and saved as fact_check_dataset_20250403_165317.csv\n",
            "True claims: 12\n",
            "False claims: 80\n",
            "\n",
            "Sample of the dataset:\n",
            "                                            headline rating\n",
            "0  BSP Chief Mayawati saying that she will retire...  False\n",
            "1  Viral video shows IPS officer Shailjakant Mish...  False\n",
            "2  \"Pro-US/Trump political party won Greenland's ...  False\n",
            "3  Banksy, the epic UK-based artist and political...  False\n",
            "4  â€œChina believes that the elections [in Tajikis...  False\n",
            "5  The prime minister was not standing in front o...  False\n",
            "6  In March 2025, billionaire Elon Musk, a close ...   True\n",
            "7  The \"buying power\" of $5 has decreased by 30 p...  False\n",
            "8  Democrats, including VP Kamala Harris, won onl...  False\n",
            "9  No homes have been built under Labor governmen...  False\n"
          ]
        }
      ],
      "source": [
        "def fetch_fact_checks(query=None, max_results=100):\n",
        "    \"\"\"\n",
        "    Fetch fact checks from Google Fact Check Explorer API\n",
        "    \"\"\"\n",
        "    base_url = \"https://factchecktools.googleapis.com/v1alpha1/claims:search\"\n",
        "\n",
        "    params = {\n",
        "        \"key\":\"<API KEY>\",  # Replace with your actual API key\n",
        "        \"maxAgeDays\": 30,  # Get fact checks from the last 30 days\n",
        "        \"pageSize\": max_results,\n",
        "        \"languageCode\": \"en\"\n",
        "    }\n",
        "\n",
        "    if query:\n",
        "        params[\"query\"] = query\n",
        "\n",
        "    response = requests.get(base_url, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error fetching data: {response.status_code}\")\n",
        "        print(response.text)\n",
        "        return None\n",
        "\n",
        "def simplify_rating(rating_text):\n",
        "    \"\"\"\n",
        "    Convert various rating texts to simple True/False\n",
        "    \"\"\"\n",
        "    # Common false ratings\n",
        "    false_ratings = [\n",
        "        \"false\", \"mostly false\", \"incorrect\", \"inaccurate\", \"misleading\",\n",
        "        \"pants on fire\", \"fake\", \"fiction\", \"hoax\", \"conspiracy\", \"untrue\"\n",
        "    ]\n",
        "\n",
        "    # Common true ratings\n",
        "    true_ratings = [\n",
        "        \"true\", \"mostly true\", \"correct\", \"accurate\", \"fact\", \"verified\"\n",
        "    ]\n",
        "\n",
        "    rating_lower = rating_text.lower()\n",
        "\n",
        "    for false_term in false_ratings:\n",
        "        if false_term in rating_lower:\n",
        "            return \"False\"\n",
        "\n",
        "    for true_term in true_ratings:\n",
        "        if true_term in rating_lower:\n",
        "            return \"True\"\n",
        "\n",
        "    # For mixed, partly true/false, or unclear ratings\n",
        "    return \"Mixed\"\n",
        "\n",
        "def create_fact_check_dataset(queries=None):\n",
        "    \"\"\"\n",
        "    Create a dataset of fact-checked headlines with True/False labels\n",
        "    \"\"\"\n",
        "    if queries is None:\n",
        "        queries = [\"politics\", \"health\", \"economy\", \"climate\", \"technology\"]\n",
        "\n",
        "    all_claims = []\n",
        "\n",
        "    for query in queries:\n",
        "        print(f\"Fetching fact checks for query: {query}\")\n",
        "        results = fetch_fact_checks(query)\n",
        "\n",
        "        if results and \"claims\" in results:\n",
        "            all_claims.extend(results[\"claims\"])\n",
        "\n",
        "    # Also get recent fact checks without specific query\n",
        "    recent_results = fetch_fact_checks()\n",
        "    if recent_results and \"claims\" in recent_results:\n",
        "        all_claims.extend(recent_results[\"claims\"])\n",
        "\n",
        "    # Remove duplicates based on claim text\n",
        "    unique_claims = []\n",
        "    seen_claims = set()\n",
        "\n",
        "    for claim in all_claims:\n",
        "        if claim[\"text\"] not in seen_claims:\n",
        "            seen_claims.add(claim[\"text\"])\n",
        "            unique_claims.append(claim)\n",
        "\n",
        "    # Create dataset\n",
        "    data = []\n",
        "    for claim in unique_claims:\n",
        "        # Skip if no review or rating\n",
        "        if \"claimReview\" not in claim or not claim[\"claimReview\"]:\n",
        "            continue\n",
        "\n",
        "        review = claim[\"claimReview\"][0]  # Take the first review\n",
        "\n",
        "        if \"textualRating\" not in review:\n",
        "            continue\n",
        "\n",
        "        headline = claim[\"text\"]\n",
        "        rating_text = review[\"textualRating\"]\n",
        "        publisher = review.get(\"publisher\", {}).get(\"name\", \"Unknown\")\n",
        "        review_url = review.get(\"url\", \"\")\n",
        "        date = review.get(\"reviewDate\", \"\")\n",
        "\n",
        "        simplified_rating = simplify_rating(rating_text)\n",
        "\n",
        "        # Skip mixed ratings for a clean True/False dataset\n",
        "        if simplified_rating == \"Mixed\":\n",
        "            continue\n",
        "\n",
        "        data.append({\n",
        "            \"headline\": headline,\n",
        "            \"original_rating\": rating_text,\n",
        "            \"rating\": simplified_rating,\n",
        "            \"fact_checker\": publisher,\n",
        "            \"review_url\": review_url,\n",
        "            \"review_date\": date\n",
        "        })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Save to CSV\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    filename = f\"fact_check_dataset_{timestamp}.csv\"\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "    print(f\"Dataset created with {len(df)} entries and saved as {filename}\")\n",
        "    print(f\"True claims: {sum(df['rating'] == 'True')}\")\n",
        "    print(f\"False claims: {sum(df['rating'] == 'False')}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define topics to search for\n",
        "    topics = [\n",
        "        \"politics\", \"election\", \"economy\", \"climate\",\n",
        "        \"health\", \"immigration\",\n",
        "        \"war\", \"military\", \"technology\", \"social media\"\n",
        "    ]\n",
        "\n",
        "    # Create the dataset\n",
        "    dataset = create_fact_check_dataset(topics)\n",
        "\n",
        "    # Display sample of the dataset\n",
        "    print(\"\\nSample of the dataset:\")\n",
        "    print(dataset[[\"headline\", \"rating\"]].head(10))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
