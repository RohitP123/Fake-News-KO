{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33wWDJNgqSxN",
        "outputId": "0dd4f986-f70b-4662-be1e-f719012b586d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fFZENQDqGxF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'News_Category_Dataset_v3.json'"
      ],
      "metadata": {
        "id": "fw7FOaN1rCGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articles = []\n",
        "with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        article = json.loads(line)\n",
        "        articles.append(article)"
      ],
      "metadata": {
        "id": "isO6Pb6IrO_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(articles[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhwzfetLr6Ga",
        "outputId": "a240215d-151e-4223-f645-ba8daadfd967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'link': 'https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9', 'headline': 'Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters', 'category': 'U.S. NEWS', 'short_description': 'Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.', 'authors': 'Carla K. Johnson, AP', 'date': '2022-09-23'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing:\n",
        "headlines = []\n",
        "metadata = []\n",
        "\n",
        "for art in articles:\n",
        "    headline = art['headline'].strip().lower()\n",
        "    headlines.append(headline)\n",
        "    # Convert the date to a datetime object for further filtering if needed.\n",
        "    art_date = art.get('date', None)\n",
        "    if art_date:\n",
        "        try:\n",
        "            art_date = datetime.strptime(art_date, '%Y-%m-%d')\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing date for article: {art_date} | {e}\")\n",
        "    metadata.append({\n",
        "        'link': art.get('link', ''),\n",
        "        'date': art_date,\n",
        "        'category': art.get('category', ''),\n",
        "        'short_description': art.get('short_description', ''),\n",
        "        'authors': art.get('authors', '')\n",
        "    })\n"
      ],
      "metadata": {
        "id": "MJ3XpfTHri3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(headlines[0])\n",
        "print(metadata[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr9TRER2sI1X",
        "outputId": "55939bc0-2a4e-4213-b889-235105179616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "over 4 million americans roll up sleeves for omicron-targeted covid boosters\n",
            "{'link': 'https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9', 'date': datetime.datetime(2022, 9, 23, 0, 0), 'category': 'U.S. NEWS', 'short_description': 'Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.', 'authors': 'Carla K. Johnson, AP'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Embeddings\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Process 1k at a time\n",
        "batch_size = 1000\n",
        "all_embeddings = []\n",
        "total = len(headlines)\n",
        "\n",
        "for i in range(0, total, batch_size):\n",
        "    batch = headlines[i:i + batch_size]\n",
        "    batch_embeddings = model.encode(batch, convert_to_numpy=True)\n",
        "    all_embeddings.append(batch_embeddings)\n",
        "    processed = min(i + batch_size, total)\n",
        "    print(f\"Processed {processed} / {total} embeddings.\")\n",
        "\n",
        "# Stack all embeddings into a single numpy array\n",
        "embeddings = np.vstack(all_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-xFk2-DsQ--",
        "outputId": "5c5a13ed-daf7-42f6-9f08-0c38cfe5e483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1000 / 209527 embeddings.\n",
            "Processed 2000 / 209527 embeddings.\n",
            "Processed 3000 / 209527 embeddings.\n",
            "Processed 4000 / 209527 embeddings.\n",
            "Processed 5000 / 209527 embeddings.\n",
            "Processed 6000 / 209527 embeddings.\n",
            "Processed 7000 / 209527 embeddings.\n",
            "Processed 8000 / 209527 embeddings.\n",
            "Processed 9000 / 209527 embeddings.\n",
            "Processed 10000 / 209527 embeddings.\n",
            "Processed 11000 / 209527 embeddings.\n",
            "Processed 12000 / 209527 embeddings.\n",
            "Processed 13000 / 209527 embeddings.\n",
            "Processed 14000 / 209527 embeddings.\n",
            "Processed 15000 / 209527 embeddings.\n",
            "Processed 16000 / 209527 embeddings.\n",
            "Processed 17000 / 209527 embeddings.\n",
            "Processed 18000 / 209527 embeddings.\n",
            "Processed 19000 / 209527 embeddings.\n",
            "Processed 20000 / 209527 embeddings.\n",
            "Processed 21000 / 209527 embeddings.\n",
            "Processed 22000 / 209527 embeddings.\n",
            "Processed 23000 / 209527 embeddings.\n",
            "Processed 24000 / 209527 embeddings.\n",
            "Processed 25000 / 209527 embeddings.\n",
            "Processed 26000 / 209527 embeddings.\n",
            "Processed 27000 / 209527 embeddings.\n",
            "Processed 28000 / 209527 embeddings.\n",
            "Processed 29000 / 209527 embeddings.\n",
            "Processed 30000 / 209527 embeddings.\n",
            "Processed 31000 / 209527 embeddings.\n",
            "Processed 32000 / 209527 embeddings.\n",
            "Processed 33000 / 209527 embeddings.\n",
            "Processed 34000 / 209527 embeddings.\n",
            "Processed 35000 / 209527 embeddings.\n",
            "Processed 36000 / 209527 embeddings.\n",
            "Processed 37000 / 209527 embeddings.\n",
            "Processed 38000 / 209527 embeddings.\n",
            "Processed 39000 / 209527 embeddings.\n",
            "Processed 40000 / 209527 embeddings.\n",
            "Processed 41000 / 209527 embeddings.\n",
            "Processed 42000 / 209527 embeddings.\n",
            "Processed 43000 / 209527 embeddings.\n",
            "Processed 44000 / 209527 embeddings.\n",
            "Processed 45000 / 209527 embeddings.\n",
            "Processed 46000 / 209527 embeddings.\n",
            "Processed 47000 / 209527 embeddings.\n",
            "Processed 48000 / 209527 embeddings.\n",
            "Processed 49000 / 209527 embeddings.\n",
            "Processed 50000 / 209527 embeddings.\n",
            "Processed 51000 / 209527 embeddings.\n",
            "Processed 52000 / 209527 embeddings.\n",
            "Processed 53000 / 209527 embeddings.\n",
            "Processed 54000 / 209527 embeddings.\n",
            "Processed 55000 / 209527 embeddings.\n",
            "Processed 56000 / 209527 embeddings.\n",
            "Processed 57000 / 209527 embeddings.\n",
            "Processed 58000 / 209527 embeddings.\n",
            "Processed 59000 / 209527 embeddings.\n",
            "Processed 60000 / 209527 embeddings.\n",
            "Processed 61000 / 209527 embeddings.\n",
            "Processed 62000 / 209527 embeddings.\n",
            "Processed 63000 / 209527 embeddings.\n",
            "Processed 64000 / 209527 embeddings.\n",
            "Processed 65000 / 209527 embeddings.\n",
            "Processed 66000 / 209527 embeddings.\n",
            "Processed 67000 / 209527 embeddings.\n",
            "Processed 68000 / 209527 embeddings.\n",
            "Processed 69000 / 209527 embeddings.\n",
            "Processed 70000 / 209527 embeddings.\n",
            "Processed 71000 / 209527 embeddings.\n",
            "Processed 72000 / 209527 embeddings.\n",
            "Processed 73000 / 209527 embeddings.\n",
            "Processed 74000 / 209527 embeddings.\n",
            "Processed 75000 / 209527 embeddings.\n",
            "Processed 76000 / 209527 embeddings.\n",
            "Processed 77000 / 209527 embeddings.\n",
            "Processed 78000 / 209527 embeddings.\n",
            "Processed 79000 / 209527 embeddings.\n",
            "Processed 80000 / 209527 embeddings.\n",
            "Processed 81000 / 209527 embeddings.\n",
            "Processed 82000 / 209527 embeddings.\n",
            "Processed 83000 / 209527 embeddings.\n",
            "Processed 84000 / 209527 embeddings.\n",
            "Processed 85000 / 209527 embeddings.\n",
            "Processed 86000 / 209527 embeddings.\n",
            "Processed 87000 / 209527 embeddings.\n",
            "Processed 88000 / 209527 embeddings.\n",
            "Processed 89000 / 209527 embeddings.\n",
            "Processed 90000 / 209527 embeddings.\n",
            "Processed 91000 / 209527 embeddings.\n",
            "Processed 92000 / 209527 embeddings.\n",
            "Processed 93000 / 209527 embeddings.\n",
            "Processed 94000 / 209527 embeddings.\n",
            "Processed 95000 / 209527 embeddings.\n",
            "Processed 96000 / 209527 embeddings.\n",
            "Processed 97000 / 209527 embeddings.\n",
            "Processed 98000 / 209527 embeddings.\n",
            "Processed 99000 / 209527 embeddings.\n",
            "Processed 100000 / 209527 embeddings.\n",
            "Processed 101000 / 209527 embeddings.\n",
            "Processed 102000 / 209527 embeddings.\n",
            "Processed 103000 / 209527 embeddings.\n",
            "Processed 104000 / 209527 embeddings.\n",
            "Processed 105000 / 209527 embeddings.\n",
            "Processed 106000 / 209527 embeddings.\n",
            "Processed 107000 / 209527 embeddings.\n",
            "Processed 108000 / 209527 embeddings.\n",
            "Processed 109000 / 209527 embeddings.\n",
            "Processed 110000 / 209527 embeddings.\n",
            "Processed 111000 / 209527 embeddings.\n",
            "Processed 112000 / 209527 embeddings.\n",
            "Processed 113000 / 209527 embeddings.\n",
            "Processed 114000 / 209527 embeddings.\n",
            "Processed 115000 / 209527 embeddings.\n",
            "Processed 116000 / 209527 embeddings.\n",
            "Processed 117000 / 209527 embeddings.\n",
            "Processed 118000 / 209527 embeddings.\n",
            "Processed 119000 / 209527 embeddings.\n",
            "Processed 120000 / 209527 embeddings.\n",
            "Processed 121000 / 209527 embeddings.\n",
            "Processed 122000 / 209527 embeddings.\n",
            "Processed 123000 / 209527 embeddings.\n",
            "Processed 124000 / 209527 embeddings.\n",
            "Processed 125000 / 209527 embeddings.\n",
            "Processed 126000 / 209527 embeddings.\n",
            "Processed 127000 / 209527 embeddings.\n",
            "Processed 128000 / 209527 embeddings.\n",
            "Processed 129000 / 209527 embeddings.\n",
            "Processed 130000 / 209527 embeddings.\n",
            "Processed 131000 / 209527 embeddings.\n",
            "Processed 132000 / 209527 embeddings.\n",
            "Processed 133000 / 209527 embeddings.\n",
            "Processed 134000 / 209527 embeddings.\n",
            "Processed 135000 / 209527 embeddings.\n",
            "Processed 136000 / 209527 embeddings.\n",
            "Processed 137000 / 209527 embeddings.\n",
            "Processed 138000 / 209527 embeddings.\n",
            "Processed 139000 / 209527 embeddings.\n",
            "Processed 140000 / 209527 embeddings.\n",
            "Processed 141000 / 209527 embeddings.\n",
            "Processed 142000 / 209527 embeddings.\n",
            "Processed 143000 / 209527 embeddings.\n",
            "Processed 144000 / 209527 embeddings.\n",
            "Processed 145000 / 209527 embeddings.\n",
            "Processed 146000 / 209527 embeddings.\n",
            "Processed 147000 / 209527 embeddings.\n",
            "Processed 148000 / 209527 embeddings.\n",
            "Processed 149000 / 209527 embeddings.\n",
            "Processed 150000 / 209527 embeddings.\n",
            "Processed 151000 / 209527 embeddings.\n",
            "Processed 152000 / 209527 embeddings.\n",
            "Processed 153000 / 209527 embeddings.\n",
            "Processed 154000 / 209527 embeddings.\n",
            "Processed 155000 / 209527 embeddings.\n",
            "Processed 156000 / 209527 embeddings.\n",
            "Processed 157000 / 209527 embeddings.\n",
            "Processed 158000 / 209527 embeddings.\n",
            "Processed 159000 / 209527 embeddings.\n",
            "Processed 160000 / 209527 embeddings.\n",
            "Processed 161000 / 209527 embeddings.\n",
            "Processed 162000 / 209527 embeddings.\n",
            "Processed 163000 / 209527 embeddings.\n",
            "Processed 164000 / 209527 embeddings.\n",
            "Processed 165000 / 209527 embeddings.\n",
            "Processed 166000 / 209527 embeddings.\n",
            "Processed 167000 / 209527 embeddings.\n",
            "Processed 168000 / 209527 embeddings.\n",
            "Processed 169000 / 209527 embeddings.\n",
            "Processed 170000 / 209527 embeddings.\n",
            "Processed 171000 / 209527 embeddings.\n",
            "Processed 172000 / 209527 embeddings.\n",
            "Processed 173000 / 209527 embeddings.\n",
            "Processed 174000 / 209527 embeddings.\n",
            "Processed 175000 / 209527 embeddings.\n",
            "Processed 176000 / 209527 embeddings.\n",
            "Processed 177000 / 209527 embeddings.\n",
            "Processed 178000 / 209527 embeddings.\n",
            "Processed 179000 / 209527 embeddings.\n",
            "Processed 180000 / 209527 embeddings.\n",
            "Processed 181000 / 209527 embeddings.\n",
            "Processed 182000 / 209527 embeddings.\n",
            "Processed 183000 / 209527 embeddings.\n",
            "Processed 184000 / 209527 embeddings.\n",
            "Processed 185000 / 209527 embeddings.\n",
            "Processed 186000 / 209527 embeddings.\n",
            "Processed 187000 / 209527 embeddings.\n",
            "Processed 188000 / 209527 embeddings.\n",
            "Processed 189000 / 209527 embeddings.\n",
            "Processed 190000 / 209527 embeddings.\n",
            "Processed 191000 / 209527 embeddings.\n",
            "Processed 192000 / 209527 embeddings.\n",
            "Processed 193000 / 209527 embeddings.\n",
            "Processed 194000 / 209527 embeddings.\n",
            "Processed 195000 / 209527 embeddings.\n",
            "Processed 196000 / 209527 embeddings.\n",
            "Processed 197000 / 209527 embeddings.\n",
            "Processed 198000 / 209527 embeddings.\n",
            "Processed 199000 / 209527 embeddings.\n",
            "Processed 200000 / 209527 embeddings.\n",
            "Processed 201000 / 209527 embeddings.\n",
            "Processed 202000 / 209527 embeddings.\n",
            "Processed 203000 / 209527 embeddings.\n",
            "Processed 204000 / 209527 embeddings.\n",
            "Processed 205000 / 209527 embeddings.\n",
            "Processed 206000 / 209527 embeddings.\n",
            "Processed 207000 / 209527 embeddings.\n",
            "Processed 208000 / 209527 embeddings.\n",
            "Processed 209000 / 209527 embeddings.\n",
            "Processed 209527 / 209527 embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vFtGauetrw1",
        "outputId": "b9759396-6c36-4643-887b-4bcecf1b44c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(209527, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Faiss Index\n",
        "\n",
        "embedding_dim = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "# Add embeddings to the index\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"Number of articles indexed: {index.ntotal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlFEn59wtdR_",
        "outputId": "b7594d74-5f5c-42c6-f2ca-bebe3bf1bd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of articles indexed: 209527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save index\n",
        "import pickle\n",
        "faiss.write_index(index, '/content/faiss_index.index')\n",
        "with open('/content/metadata.pkl', 'wb') as f:\n",
        "    pickle.dump(metadata, f)\n",
        "print(\"Index and metadata saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Tdoj_zE3PV",
        "outputId": "5cb2f900-e96c-4519-cd35-461cb850e3ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index and metadata saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Function\n",
        "def search_similar_articles(query_headline, k=3):\n",
        "    query = query_headline.strip().lower()\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "\n",
        "    results = []\n",
        "    for rank, idx in enumerate(indices[0]):\n",
        "        results.append({\n",
        "            'headline': headlines[idx],\n",
        "            'metadata': metadata[idx],\n",
        "            'distance': distances[0][rank]\n",
        "        })\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "qraiNH6zFcBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "test_query = \"Over 4 million Americans get Omicron boosters\"\n",
        "results = search_similar_articles(test_query, k=3)\n",
        "print(\"Top similar articles:\")\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAxO4FbCFfpN",
        "outputId": "4e1a9491-2645-45c3-8a08-7f2023cf888b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top similar articles:\n",
            "{'headline': 'over 4 million americans roll up sleeves for omicron-targeted covid boosters', 'metadata': {'link': 'https://www.huffpost.com/entry/covid-boosters-uptake-us_n_632d719ee4b087fae6feaac9', 'date': datetime.datetime(2022, 9, 23, 0, 0), 'category': 'U.S. NEWS', 'short_description': 'Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.', 'authors': 'Carla K. Johnson, AP'}, 'distance': 0.5057889}\n",
            "{'headline': 'u.s. added 678,000 jobs in february as omicron eases', 'metadata': {'link': 'https://www.huffpost.com/entry/february-2022-jobs-report_n_6222140ae4b012a262898f05', 'date': datetime.datetime(2022, 3, 4, 0, 0), 'category': 'BUSINESS', 'short_description': 'Unemployment fell to 3.8% as the economy continues its pandemic recovery.', 'authors': 'Christopher Rugaber, AP'}, 'distance': 0.9158522}\n",
            "{'headline': 'more countries scramble to curb omicron', 'metadata': {'link': 'https://www.huffpost.com/entry/countries-scramble-omicron-covid-variant_n_61a23574e4b025be1ae9e90f', 'date': datetime.datetime(2021, 11, 27, 0, 0), 'category': 'WORLD NEWS', 'short_description': 'The new COVID-19 variant was identified in South Africa two weeks ago.', 'authors': 'Mike Corder and Pan Pylas, AP'}, 'distance': 0.9324627}\n"
          ]
        }
      ]
    }
  ]
}