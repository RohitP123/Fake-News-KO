{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Qt5oCDjPH0",
        "outputId": "57ba171a-f9ed-4fb8-ec3c-2ada9122b7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets torch scikit-learn pandas matplotlib faiss-cpu sentence-transformers\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import pickle\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-bTouH-mnsP",
        "outputId": "8dbeed84-869f-4be0-f4af-2b4942570ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c8191587130>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading & Splitting\n",
        "df = pd.read_csv(\"Liar2_combined.csv\", header=0)\n",
        "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d', errors='coerce')\n",
        "df = df.dropna(subset=['date'])\n",
        "print(df.head())\n",
        "\n",
        "# Define date ranges\n",
        "baseline_start, baseline_end = '2007-01-01', '2015-12-31'\n",
        "update1_start, update1_end   = '2016-01-01', '2017-12-31'\n",
        "update2_start, update2_end   = '2018-01-01', '2019-12-31'\n",
        "update3_start, update3_end   = '2020-01-01', '2021-12-31'\n",
        "update4_start, update4_end   = '2022-01-01', '2022-12-31'\n",
        "test_start, test_end         = '2023-01-01', '2023-12-31'\n",
        "\n",
        "# Create splits\n",
        "baseline_df = df[(df['date'] >= baseline_start) & (df['date'] <= baseline_end)].copy()\n",
        "update1_df  = df[(df['date'] >= update1_start)  & (df['date'] <= update1_end)].copy()\n",
        "update2_df  = df[(df['date'] >= update2_start)  & (df['date'] <= update2_end)].copy()\n",
        "update3_df  = df[(df['date'] >= update3_start)  & (df['date'] <= update3_end)].copy()\n",
        "update4_df  = df[(df['date'] >= update4_start)  & (df['date'] <= update4_end)].copy()\n",
        "test_df     = df[(df['date'] >= test_start)     & (df['date'] <= test_end)].copy()\n",
        "\n",
        "print(\"Baseline samples:\", len(baseline_df))\n",
        "print(\"Update 1 samples:\", len(update1_df))\n",
        "print(\"Update 2 samples:\", len(update2_df))\n",
        "print(\"Update 3 samples:\", len(update3_df))\n",
        "print(\"Update 4 samples:\", len(update4_df))\n",
        "print(\"Test samples:\", len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IZak3bjmouY",
        "outputId": "3fbd046b-14e3-4caf-d883-abaf8e436e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                              title       date\n",
            "0      1  90 percent of Americans \"support universal bac... 2017-10-02\n",
            "1      0  Last year was one of the deadliest years ever ... 2017-05-19\n",
            "2      0  Bernie Sanders's plan is \"to raise your taxes ... 2015-10-28\n",
            "3      1  Voter ID is supported by an overwhelming major... 2021-12-08\n",
            "4      0  Says Barack Obama \"robbed Medicare (of) $716 b... 2012-08-12\n",
            "Baseline samples: 10932\n",
            "Update 1 samples: 3031\n",
            "Update 2 samples: 2730\n",
            "Update 3 samples: 3772\n",
            "Update 4 samples: 1688\n",
            "Test samples: 807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize_function(texts):\n",
        "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "def prepare_dataset(df_subset):\n",
        "    texts = df_subset['title'].tolist()\n",
        "    labels = df_subset['label'].tolist()\n",
        "    encodings = tokenize_function(texts)\n",
        "    dataset = Dataset.from_dict({\n",
        "        \"input_ids\": encodings[\"input_ids\"],\n",
        "        \"attention_mask\": encodings[\"attention_mask\"],\n",
        "        \"labels\": labels,\n",
        "    })\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Tl-Qb6ywm3Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Continual Learning Training Functions\n",
        "baseline_training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_baseline\",\n",
        "    run_name=\"baseline_training\",\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        ")\n",
        "\n",
        "update_training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_continual\",\n",
        "    run_name=\"continual_update\",\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        ")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "def fine_tune_on_update(model, update_dataset, update_name, eval_dataset):\n",
        "    print(f\"\\n--- Fine-tuning on {update_name} ---\")\n",
        "    update_trainer = Trainer(\n",
        "        model=model,\n",
        "        args=update_training_args,\n",
        "        train_dataset=update_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    update_trainer.train()\n",
        "    results = update_trainer.evaluate()\n",
        "    print(f\"{update_name} - Test Accuracy: {results['eval_accuracy']:.4f}\")\n",
        "\n",
        "    preds = update_trainer.predict(eval_dataset).predictions\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "    print(classification_report(eval_dataset[\"labels\"], pred_labels, target_names=[\"Fake\", \"Real\"]))\n",
        "\n",
        "    model_save_path = f\"fine_tuned_bert_{update_name.replace(' ', '_').lower()}\"\n",
        "    model.save_pretrained(model_save_path)\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    shutil.make_archive(model_save_path, 'zip', model_save_path)\n",
        "    return model\n",
        "\n",
        "def evaluate_on_period(model, period_name, df_period):\n",
        "    print(f\"\\n--- Evaluating on {period_name} ---\")\n",
        "    dataset = prepare_dataset(df_period)\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=baseline_training_args,\n",
        "        eval_dataset=dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    results = trainer.evaluate()\n",
        "    preds = trainer.predict(dataset).predictions\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "    report = classification_report(dataset[\"labels\"], pred_labels, target_names=[\"Fake\", \"Real\"])\n",
        "    print(f\"{period_name} Accuracy: {results['eval_accuracy']:.4f}\")\n",
        "    print(report)\n",
        "    return results, report\n",
        "\n",
        "def rolling_evaluation_CL(model, model_version):\n",
        "    # Define the rolling evaluation order for the Continual Learning pipeline.\n",
        "    # For a given model version, we evaluate on all subsequent time periods.\n",
        "    rolling_mapping = {\n",
        "        \"Baseline\": [(\"Update 1\", update1_df), (\"Update 2\", update2_df), (\"Update 3\", update3_df), (\"Update 4\", update4_df), (\"Test\", test_df)],\n",
        "        \"Update 1\": [(\"Update 1\", update1_df), (\"Update 2\", update2_df), (\"Update 3\", update3_df), (\"Update 4\", update4_df), (\"Test\", test_df)],\n",
        "        \"Update 2\": [(\"Update 2\", update2_df), (\"Update 3\", update3_df), (\"Update 4\", update4_df), (\"Test\", test_df)],\n",
        "        \"Update 3\": [(\"Update 3\", update3_df), (\"Update 4\", update4_df), (\"Test\", test_df)],\n",
        "        \"Update 4\": [(\"Update 4\", update4_df), (\"Test\", test_df)],\n",
        "    }\n",
        "    evaluations = {}\n",
        "    if model_version in rolling_mapping:\n",
        "        for period_name, df_period in rolling_mapping[model_version]:\n",
        "            evaluations[period_name] = evaluate_on_period(model, period_name, df_period)\n",
        "    else:\n",
        "        print(f\"No rolling evaluation defined for model version: {model_version}\")\n",
        "    return evaluations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9Y5eQLim_Na",
        "outputId": "32be7d44-7cd1-4d22-dbc4-ebafcb1163a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Continual Learning Experiments"
      ],
      "metadata": {
        "id": "AErENWPtqrwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_dataset = prepare_dataset(baseline_df)\n",
        "test_dataset_CL = prepare_dataset(test_df)"
      ],
      "metadata": {
        "id": "MEvcH4IHqmtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Baseline Model\n",
        "model_CL = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "trainer_CL = Trainer(\n",
        "    model=model_CL,\n",
        "    args=baseline_training_args,\n",
        "    train_dataset=baseline_dataset,\n",
        "    eval_dataset=test_dataset_CL,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "trainer_CL.train()\n",
        "baseline_results = trainer_CL.evaluate()\n",
        "print(f\"Baseline Test Accuracy: {baseline_results['eval_accuracy']:.4f}\")\n",
        "baseline_preds = trainer_CL.predict(test_dataset_CL).predictions\n",
        "baseline_pred_labels = np.argmax(baseline_preds, axis=1)\n",
        "print(classification_report(test_dataset_CL[\"labels\"], baseline_pred_labels, target_names=[\"Fake\", \"Real\"]))\n",
        "\n",
        "# Save baseline model\n",
        "model_CL.save_pretrained(\"fine_tuned_bert_baseline_CL\")\n",
        "tokenizer.save_pretrained(\"fine_tuned_bert_baseline_CL\")\n",
        "shutil.make_archive('fine_tuned_bert_baseline_CL', 'zip', \"fine_tuned_bert_baseline_CL\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "RuV-zvkkqzBn",
        "outputId": "d56cbabd-9cec-4d04-eb7b-17cda87fa857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4101' max='4101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4101/4101 13:52, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.677900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.667300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.634700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.601800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.581400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.494600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.432900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.412100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Test Accuracy: 0.7695\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.76      0.85       705\n",
            "        Real       0.33      0.80      0.47       102\n",
            "\n",
            "    accuracy                           0.77       807\n",
            "   macro avg       0.65      0.78      0.66       807\n",
            "weighted avg       0.88      0.77      0.80       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/fine_tuned_bert_baseline_CL.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rolling evaluation for baseline model (evaluate on later periods)\n",
        "print(\"\\nRolling Evaluation for Baseline Model:\")\n",
        "rolling_evaluation_CL(model_CL, \"Baseline\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GrUJixprq6pa",
        "outputId": "228dfee1-1f73-42fd-e927-b3bba1e7cc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rolling Evaluation for Baseline Model:\n",
            "\n",
            "--- Evaluating on Update 1 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 1 Accuracy: 0.6358\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.69      0.52      0.60      1555\n",
            "        Real       0.60      0.76      0.67      1476\n",
            "\n",
            "    accuracy                           0.64      3031\n",
            "   macro avg       0.65      0.64      0.63      3031\n",
            "weighted avg       0.65      0.64      0.63      3031\n",
            "\n",
            "\n",
            "--- Evaluating on Update 2 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 2 Accuracy: 0.6487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.79      0.62      0.69      1759\n",
            "        Real       0.50      0.70      0.59       971\n",
            "\n",
            "    accuracy                           0.65      2730\n",
            "   macro avg       0.65      0.66      0.64      2730\n",
            "weighted avg       0.69      0.65      0.66      2730\n",
            "\n",
            "\n",
            "--- Evaluating on Update 3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 3 Accuracy: 0.6972\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.88      0.72      0.79      3006\n",
            "        Real       0.36      0.62      0.45       766\n",
            "\n",
            "    accuracy                           0.70      3772\n",
            "   macro avg       0.62      0.67      0.62      3772\n",
            "weighted avg       0.77      0.70      0.72      3772\n",
            "\n",
            "\n",
            "--- Evaluating on Update 4 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 4 Accuracy: 0.7068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.92      0.71      0.80      1427\n",
            "        Real       0.30      0.67      0.42       261\n",
            "\n",
            "    accuracy                           0.71      1688\n",
            "   macro avg       0.61      0.69      0.61      1688\n",
            "weighted avg       0.83      0.71      0.74      1688\n",
            "\n",
            "\n",
            "--- Evaluating on Test ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7695\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.76      0.85       705\n",
            "        Real       0.33      0.80      0.47       102\n",
            "\n",
            "    accuracy                           0.77       807\n",
            "   macro avg       0.65      0.78      0.66       807\n",
            "weighted avg       0.88      0.77      0.80       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 1': ({'eval_loss': 0.8237868547439575,\n",
              "   'eval_model_preparation_time': 0.0043,\n",
              "   'eval_accuracy': 0.6357637743319037,\n",
              "   'eval_runtime': 20.6322,\n",
              "   'eval_samples_per_second': 146.906,\n",
              "   'eval_steps_per_second': 18.369},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.69      0.52      0.60      1555\\n        Real       0.60      0.76      0.67      1476\\n\\n    accuracy                           0.64      3031\\n   macro avg       0.65      0.64      0.63      3031\\nweighted avg       0.65      0.64      0.63      3031\\n'),\n",
              " 'Update 2': ({'eval_loss': 0.7852499485015869,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.6487179487179487,\n",
              "   'eval_runtime': 19.0533,\n",
              "   'eval_samples_per_second': 143.282,\n",
              "   'eval_steps_per_second': 17.95},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.79      0.62      0.69      1759\\n        Real       0.50      0.70      0.59       971\\n\\n    accuracy                           0.65      2730\\n   macro avg       0.65      0.66      0.64      2730\\nweighted avg       0.69      0.65      0.66      2730\\n'),\n",
              " 'Update 3': ({'eval_loss': 0.6783198118209839,\n",
              "   'eval_model_preparation_time': 0.0026,\n",
              "   'eval_accuracy': 0.6972428419936373,\n",
              "   'eval_runtime': 26.1324,\n",
              "   'eval_samples_per_second': 144.342,\n",
              "   'eval_steps_per_second': 18.062},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.88      0.72      0.79      3006\\n        Real       0.36      0.62      0.45       766\\n\\n    accuracy                           0.70      3772\\n   macro avg       0.62      0.67      0.62      3772\\nweighted avg       0.77      0.70      0.72      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.6709794402122498,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.7067535545023697,\n",
              "   'eval_runtime': 11.7847,\n",
              "   'eval_samples_per_second': 143.236,\n",
              "   'eval_steps_per_second': 17.905},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.92      0.71      0.80      1427\\n        Real       0.30      0.67      0.42       261\\n\\n    accuracy                           0.71      1688\\n   macro avg       0.61      0.69      0.61      1688\\nweighted avg       0.83      0.71      0.74      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.5308418869972229,\n",
              "   'eval_model_preparation_time': 0.0026,\n",
              "   'eval_accuracy': 0.7695167286245354,\n",
              "   'eval_runtime': 5.6263,\n",
              "   'eval_samples_per_second': 143.434,\n",
              "   'eval_steps_per_second': 17.951},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.96      0.76      0.85       705\\n        Real       0.33      0.80      0.47       102\\n\\n    accuracy                           0.77       807\\n   macro avg       0.65      0.78      0.66       807\\nweighted avg       0.88      0.77      0.80       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 1\n",
        "update1_dataset = prepare_dataset(update1_df)\n",
        "model_CL = fine_tune_on_update(model_CL, update1_dataset, \"Update 1\", test_dataset_CL)\n",
        "print(\"\\nRolling Evaluation for Update 1 Model:\")\n",
        "rolling_evaluation_CL(model_CL, \"Update 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rh4Pj7Heq9gO",
        "outputId": "46aea260-5a18-4b44-d62e-22f0a858e805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning on Update 1 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='758' max='758' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [758/758 02:39, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.580800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 1 - Test Accuracy: 0.8116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.82      0.88       705\n",
            "        Real       0.38      0.75      0.50       102\n",
            "\n",
            "    accuracy                           0.81       807\n",
            "   macro avg       0.67      0.78      0.69       807\n",
            "weighted avg       0.88      0.81      0.84       807\n",
            "\n",
            "\n",
            "Rolling Evaluation for Update 1 Model:\n",
            "\n",
            "--- Evaluating on Update 1 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 1 Accuracy: 0.8720\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.94      0.80      0.86      1555\n",
            "        Real       0.82      0.95      0.88      1476\n",
            "\n",
            "    accuracy                           0.87      3031\n",
            "   macro avg       0.88      0.87      0.87      3031\n",
            "weighted avg       0.88      0.87      0.87      3031\n",
            "\n",
            "\n",
            "--- Evaluating on Update 2 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 2 Accuracy: 0.6769\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.81      0.65      0.72      1759\n",
            "        Real       0.53      0.72      0.61       971\n",
            "\n",
            "    accuracy                           0.68      2730\n",
            "   macro avg       0.67      0.69      0.67      2730\n",
            "weighted avg       0.71      0.68      0.68      2730\n",
            "\n",
            "\n",
            "--- Evaluating on Update 3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 3 Accuracy: 0.7452\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.88      0.78      0.83      3006\n",
            "        Real       0.41      0.60      0.49       766\n",
            "\n",
            "    accuracy                           0.75      3772\n",
            "   macro avg       0.65      0.69      0.66      3772\n",
            "weighted avg       0.79      0.75      0.76      3772\n",
            "\n",
            "\n",
            "--- Evaluating on Update 4 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 4 Accuracy: 0.7648\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.78      0.85      1427\n",
            "        Real       0.36      0.67      0.47       261\n",
            "\n",
            "    accuracy                           0.76      1688\n",
            "   macro avg       0.64      0.73      0.66      1688\n",
            "weighted avg       0.84      0.76      0.79      1688\n",
            "\n",
            "\n",
            "--- Evaluating on Test ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.82      0.88       705\n",
            "        Real       0.38      0.75      0.50       102\n",
            "\n",
            "    accuracy                           0.81       807\n",
            "   macro avg       0.67      0.78      0.69       807\n",
            "weighted avg       0.88      0.81      0.84       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 1': ({'eval_loss': 0.3140810430049896,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.8719894424282415,\n",
              "   'eval_runtime': 20.3502,\n",
              "   'eval_samples_per_second': 148.942,\n",
              "   'eval_steps_per_second': 18.624},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.94      0.80      0.86      1555\\n        Real       0.82      0.95      0.88      1476\\n\\n    accuracy                           0.87      3031\\n   macro avg       0.88      0.87      0.87      3031\\nweighted avg       0.88      0.87      0.87      3031\\n'),\n",
              " 'Update 2': ({'eval_loss': 0.6788209080696106,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.676923076923077,\n",
              "   'eval_runtime': 18.6608,\n",
              "   'eval_samples_per_second': 146.296,\n",
              "   'eval_steps_per_second': 18.327},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.81      0.65      0.72      1759\\n        Real       0.53      0.72      0.61       971\\n\\n    accuracy                           0.68      2730\\n   macro avg       0.67      0.69      0.67      2730\\nweighted avg       0.71      0.68      0.68      2730\\n'),\n",
              " 'Update 3': ({'eval_loss': 0.5201601982116699,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.7452279957582184,\n",
              "   'eval_runtime': 26.1427,\n",
              "   'eval_samples_per_second': 144.285,\n",
              "   'eval_steps_per_second': 18.055},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.88      0.78      0.83      3006\\n        Real       0.41      0.60      0.49       766\\n\\n    accuracy                           0.75      3772\\n   macro avg       0.65      0.69      0.66      3772\\nweighted avg       0.79      0.75      0.76      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.47698697447776794,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.7648104265402843,\n",
              "   'eval_runtime': 11.7209,\n",
              "   'eval_samples_per_second': 144.016,\n",
              "   'eval_steps_per_second': 18.002},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.93      0.78      0.85      1427\\n        Real       0.36      0.67      0.47       261\\n\\n    accuracy                           0.76      1688\\n   macro avg       0.64      0.73      0.66      1688\\nweighted avg       0.84      0.76      0.79      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.3789675533771515,\n",
              "   'eval_model_preparation_time': 0.0026,\n",
              "   'eval_accuracy': 0.8116480793060719,\n",
              "   'eval_runtime': 5.6489,\n",
              "   'eval_samples_per_second': 142.86,\n",
              "   'eval_steps_per_second': 17.88},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.96      0.82      0.88       705\\n        Real       0.38      0.75      0.50       102\\n\\n    accuracy                           0.81       807\\n   macro avg       0.67      0.78      0.69       807\\nweighted avg       0.88      0.81      0.84       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 2\n",
        "update2_dataset = prepare_dataset(update2_df)\n",
        "model_CL = fine_tune_on_update(model_CL, update2_dataset, \"Update 2\", test_dataset_CL)\n",
        "print(\"\\nRolling Evaluation for Update 2 Model:\")\n",
        "rolling_evaluation_CL(model_CL, \"Update 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x8IJYhxxq_0n",
        "outputId": "0d9e60de-10e0-4e24-b882-d90793294f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning on Update 2 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [684/684 02:43, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.511100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 2 - Test Accuracy: 0.8625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.95      0.89      0.92       705\n",
            "        Real       0.47      0.67      0.55       102\n",
            "\n",
            "    accuracy                           0.86       807\n",
            "   macro avg       0.71      0.78      0.73       807\n",
            "weighted avg       0.89      0.86      0.87       807\n",
            "\n",
            "\n",
            "Rolling Evaluation for Update 2 Model:\n",
            "\n",
            "--- Evaluating on Update 2 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 2 Accuracy: 0.8897\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.94      0.89      0.91      1759\n",
            "        Real       0.81      0.90      0.85       971\n",
            "\n",
            "    accuracy                           0.89      2730\n",
            "   macro avg       0.88      0.89      0.88      2730\n",
            "weighted avg       0.89      0.89      0.89      2730\n",
            "\n",
            "\n",
            "--- Evaluating on Update 3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 3 Accuracy: 0.7895\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.88      0.85      0.87      3006\n",
            "        Real       0.48      0.56      0.52       766\n",
            "\n",
            "    accuracy                           0.79      3772\n",
            "   macro avg       0.68      0.70      0.69      3772\n",
            "weighted avg       0.80      0.79      0.79      3772\n",
            "\n",
            "\n",
            "--- Evaluating on Update 4 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 4 Accuracy: 0.8081\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.92      0.84      0.88      1427\n",
            "        Real       0.42      0.62      0.50       261\n",
            "\n",
            "    accuracy                           0.81      1688\n",
            "   macro avg       0.67      0.73      0.69      1688\n",
            "weighted avg       0.85      0.81      0.82      1688\n",
            "\n",
            "\n",
            "--- Evaluating on Test ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.95      0.89      0.92       705\n",
            "        Real       0.47      0.67      0.55       102\n",
            "\n",
            "    accuracy                           0.86       807\n",
            "   macro avg       0.71      0.78      0.73       807\n",
            "weighted avg       0.89      0.86      0.87       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 2': ({'eval_loss': 0.27958858013153076,\n",
              "   'eval_model_preparation_time': 0.0038,\n",
              "   'eval_accuracy': 0.8897435897435897,\n",
              "   'eval_runtime': 18.4703,\n",
              "   'eval_samples_per_second': 147.805,\n",
              "   'eval_steps_per_second': 18.516},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.94      0.89      0.91      1759\\n        Real       0.81      0.90      0.85       971\\n\\n    accuracy                           0.89      2730\\n   macro avg       0.88      0.89      0.88      2730\\nweighted avg       0.89      0.89      0.89      2730\\n'),\n",
              " 'Update 3': ({'eval_loss': 0.48752087354660034,\n",
              "   'eval_model_preparation_time': 0.0041,\n",
              "   'eval_accuracy': 0.7895015906680806,\n",
              "   'eval_runtime': 25.9039,\n",
              "   'eval_samples_per_second': 145.615,\n",
              "   'eval_steps_per_second': 18.221},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.88      0.85      0.87      3006\\n        Real       0.48      0.56      0.52       766\\n\\n    accuracy                           0.79      3772\\n   macro avg       0.68      0.70      0.69      3772\\nweighted avg       0.80      0.79      0.79      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.43007200956344604,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.8080568720379147,\n",
              "   'eval_runtime': 11.6934,\n",
              "   'eval_samples_per_second': 144.355,\n",
              "   'eval_steps_per_second': 18.044},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.92      0.84      0.88      1427\\n        Real       0.42      0.62      0.50       261\\n\\n    accuracy                           0.81      1688\\n   macro avg       0.67      0.73      0.69      1688\\nweighted avg       0.85      0.81      0.82      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.3044184744358063,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.862453531598513,\n",
              "   'eval_runtime': 5.5923,\n",
              "   'eval_samples_per_second': 144.305,\n",
              "   'eval_steps_per_second': 18.06},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.95      0.89      0.92       705\\n        Real       0.47      0.67      0.55       102\\n\\n    accuracy                           0.86       807\\n   macro avg       0.71      0.78      0.73       807\\nweighted avg       0.89      0.86      0.87       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 3\n",
        "update3_dataset = prepare_dataset(update3_df)\n",
        "model_CL = fine_tune_on_update(model_CL, update3_dataset, \"Update 3\", test_dataset_CL)\n",
        "print(\"\\nRolling Evaluation for Update 3 Model:\")\n",
        "rolling_evaluation_CL(model_CL, \"Update 3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EPsktVs0rBNc",
        "outputId": "f0127f99-ca90-4e32-c252-2704a6912963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning on Update 3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='944' max='944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [944/944 03:29, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.425900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 3 - Test Accuracy: 0.9009\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.94      0.94      0.94       705\n",
            "        Real       0.61      0.60      0.60       102\n",
            "\n",
            "    accuracy                           0.90       807\n",
            "   macro avg       0.78      0.77      0.77       807\n",
            "weighted avg       0.90      0.90      0.90       807\n",
            "\n",
            "\n",
            "Rolling Evaluation for Update 3 Model:\n",
            "\n",
            "--- Evaluating on Update 3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 3 Accuracy: 0.9380\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.95      0.98      0.96      3006\n",
            "        Real       0.89      0.79      0.84       766\n",
            "\n",
            "    accuracy                           0.94      3772\n",
            "   macro avg       0.92      0.88      0.90      3772\n",
            "weighted avg       0.94      0.94      0.94      3772\n",
            "\n",
            "\n",
            "--- Evaluating on Update 4 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 4 Accuracy: 0.8472\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.92      0.90      0.91      1427\n",
            "        Real       0.51      0.57      0.53       261\n",
            "\n",
            "    accuracy                           0.85      1688\n",
            "   macro avg       0.71      0.73      0.72      1688\n",
            "weighted avg       0.86      0.85      0.85      1688\n",
            "\n",
            "\n",
            "--- Evaluating on Test ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9009\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.94      0.94      0.94       705\n",
            "        Real       0.61      0.60      0.60       102\n",
            "\n",
            "    accuracy                           0.90       807\n",
            "   macro avg       0.78      0.77      0.77       807\n",
            "weighted avg       0.90      0.90      0.90       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 3': ({'eval_loss': 0.19403164088726044,\n",
              "   'eval_model_preparation_time': 0.0026,\n",
              "   'eval_accuracy': 0.9379639448568399,\n",
              "   'eval_runtime': 25.6986,\n",
              "   'eval_samples_per_second': 146.778,\n",
              "   'eval_steps_per_second': 18.367},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.95      0.98      0.96      3006\\n        Real       0.89      0.79      0.84       766\\n\\n    accuracy                           0.94      3772\\n   macro avg       0.92      0.88      0.90      3772\\nweighted avg       0.94      0.94      0.94      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.4446048140525818,\n",
              "   'eval_model_preparation_time': 0.003,\n",
              "   'eval_accuracy': 0.8471563981042654,\n",
              "   'eval_runtime': 11.7106,\n",
              "   'eval_samples_per_second': 144.143,\n",
              "   'eval_steps_per_second': 18.018},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.92      0.90      0.91      1427\\n        Real       0.51      0.57      0.53       261\\n\\n    accuracy                           0.85      1688\\n   macro avg       0.71      0.73      0.72      1688\\nweighted avg       0.86      0.85      0.85      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.2741725742816925,\n",
              "   'eval_model_preparation_time': 0.0026,\n",
              "   'eval_accuracy': 0.9008674101610905,\n",
              "   'eval_runtime': 5.5688,\n",
              "   'eval_samples_per_second': 144.916,\n",
              "   'eval_steps_per_second': 18.137},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.94      0.94      0.94       705\\n        Real       0.61      0.60      0.60       102\\n\\n    accuracy                           0.90       807\\n   macro avg       0.78      0.77      0.77       807\\nweighted avg       0.90      0.90      0.90       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 4\n",
        "update4_dataset = prepare_dataset(update4_df)\n",
        "model_CL = fine_tune_on_update(model_CL, update4_dataset, \"Update 4\", test_dataset_CL)\n",
        "print(\"\\nRolling Evaluation for Update 4 Model:\")\n",
        "rolling_evaluation_CL(model_CL, \"Update 4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nr3zdj_4rCi2",
        "outputId": "e4560c2a-9f65-4888-ff95-dd72446c56ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fine-tuning on Update 4 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='422' max='422' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [422/422 01:36, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 4 - Test Accuracy: 0.8996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.96      0.94       705\n",
            "        Real       0.63      0.49      0.55       102\n",
            "\n",
            "    accuracy                           0.90       807\n",
            "   macro avg       0.78      0.72      0.75       807\n",
            "weighted avg       0.89      0.90      0.89       807\n",
            "\n",
            "\n",
            "Rolling Evaluation for Update 4 Model:\n",
            "\n",
            "--- Evaluating on Update 4 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Update 4 Accuracy: 0.9532\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.98      0.97      1427\n",
            "        Real       0.89      0.80      0.84       261\n",
            "\n",
            "    accuracy                           0.95      1688\n",
            "   macro avg       0.93      0.89      0.91      1688\n",
            "weighted avg       0.95      0.95      0.95      1688\n",
            "\n",
            "\n",
            "--- Evaluating on Test ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.96      0.94       705\n",
            "        Real       0.63      0.49      0.55       102\n",
            "\n",
            "    accuracy                           0.90       807\n",
            "   macro avg       0.78      0.72      0.75       807\n",
            "weighted avg       0.89      0.90      0.89       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 4': ({'eval_loss': 0.15085896849632263,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.9531990521327014,\n",
              "   'eval_runtime': 11.4398,\n",
              "   'eval_samples_per_second': 147.555,\n",
              "   'eval_steps_per_second': 18.444},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.96      0.98      0.97      1427\\n        Real       0.89      0.80      0.84       261\\n\\n    accuracy                           0.95      1688\\n   macro avg       0.93      0.89      0.91      1688\\nweighted avg       0.95      0.95      0.95      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.302641361951828,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.8996282527881041,\n",
              "   'eval_runtime': 5.5091,\n",
              "   'eval_samples_per_second': 146.484,\n",
              "   'eval_steps_per_second': 18.333},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.93      0.96      0.94       705\\n        Real       0.63      0.49      0.55       102\\n\\n    accuracy                           0.90       807\\n   macro avg       0.78      0.72      0.75       807\\nweighted avg       0.89      0.90      0.89       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Model Experiments"
      ],
      "metadata": {
        "id": "6Jas6PE9ram4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_filename = \"faiss_indexes_new.zip\"\n",
        "extract_dir = \"faiss_indexes\"\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "print(f\"Extracted {zip_filename} to {extract_dir}\")\n",
        "\n",
        "import faiss\n",
        "index_baseline = faiss.read_index(os.path.join(extract_dir, \"faiss_index_baseline.index\"))\n",
        "index_update1 = faiss.read_index(os.path.join(extract_dir, \"faiss_index_update1.index\"))\n",
        "index_update2 = faiss.read_index(os.path.join(extract_dir, \"faiss_index_update2.index\"))\n",
        "index_update3 = faiss.read_index(os.path.join(extract_dir, \"faiss_index_update3.index\"))\n",
        "index_update4 = faiss.read_index(os.path.join(extract_dir, \"faiss_index_update4.index\"))\n",
        "print(\"FAISS indexes loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvigqM8wrVES",
        "outputId": "5fa411ab-4c71-4c66-8ca3-7cacdc93e3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted faiss_indexes_new.zip to faiss_indexes\n",
            "FAISS indexes loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"faiss_headlines_new.pkl\", \"rb\") as f:\n",
        "    headlines_data = pickle.load(f)\n",
        "headlines_baseline = headlines_data[\"baseline\"]\n",
        "headlines_update1  = headlines_data[\"update1\"]\n",
        "headlines_update2  = headlines_data[\"update2\"]\n",
        "headlines_update3  = headlines_data[\"update3\"]\n",
        "headlines_update4  = headlines_data[\"update4\"]\n",
        "print(\"Headlines loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIsJCg2drn3V",
        "outputId": "18cbcaec-6d64-4f11-c5ed-72b647567b8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Headlines loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG Dataset Class and Input Preparation\n",
        "\n",
        "def prepare_input(article, facts, tokenizer, max_length=512):\n",
        "    article_tokens = tokenizer.encode(article, add_special_tokens=False)\n",
        "    fact_tokens_list = [tokenizer.encode(fact, add_special_tokens=False) for fact in facts]\n",
        "    # Format: [CLS] article [SEP] fact1 [SEP] fact2 [SEP] ...\n",
        "    input_ids = [tokenizer.cls_token_id] + article_tokens + [tokenizer.sep_token_id]\n",
        "    token_type_ids = [0] * (len(article_tokens) + 2)\n",
        "    for fact_tokens in fact_tokens_list:\n",
        "        input_ids += fact_tokens + [tokenizer.sep_token_id]\n",
        "        token_type_ids += [1] * (len(fact_tokens) + 1)\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    if len(input_ids) > max_length:\n",
        "        input_ids = input_ids[:max_length]\n",
        "        token_type_ids = token_type_ids[:max_length]\n",
        "        attention_mask = attention_mask[:max_length]\n",
        "    else:\n",
        "        pad_length = max_length - len(input_ids)\n",
        "        input_ids += [tokenizer.pad_token_id] * pad_length\n",
        "        token_type_ids += [0] * pad_length\n",
        "        attention_mask += [0] * pad_length\n",
        "    return {\n",
        "        'input_ids': torch.tensor(input_ids),\n",
        "        'token_type_ids': torch.tensor(token_type_ids),\n",
        "        'attention_mask': torch.tensor(attention_mask)\n",
        "    }\n",
        "\n",
        "def search_similar_articles(query_headline, model, faiss_index, headlines, k=3):\n",
        "    query = query_headline.strip().lower()\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(query_embedding)\n",
        "    distances, indices = faiss_index.search(query_embedding, k)\n",
        "    results = []\n",
        "    for rank, idx in enumerate(indices[0]):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        # Combine the retrieved headline with its distance value\n",
        "        hybrid_fact = f\"{headlines[idx]} (dist: {distances[0][rank]:.4f})\"\n",
        "        results.append(hybrid_fact)\n",
        "    return results\n",
        "\n",
        "class FakeNewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, retrieval_model, faiss_index, headlines, max_length=512):\n",
        "        self.dataframe = dataframe.reset_index(drop=True)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.retrieval_model = retrieval_model\n",
        "        self.faiss_index = faiss_index\n",
        "        self.headlines = headlines\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        article = row['title']\n",
        "        label = row['label']\n",
        "        # Retrieve top 3 facts\n",
        "        facts = search_similar_articles(article, self.retrieval_model, self.faiss_index, self.headlines, k=3)\n",
        "        encoding = prepare_input(article, facts, self.tokenizer, self.max_length)\n",
        "        encoding['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "        return encoding"
      ],
      "metadata": {
        "id": "dkempnYWrpXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG Training & Evaluation Functions\n",
        "\n",
        "rag_training_args = TrainingArguments(\n",
        "    output_dir=\"./rag_results\",\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    # evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./rag_logs\",\n",
        "    logging_steps=250,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "def compute_metrics_rag(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=None)\n",
        "    report = classification_report(labels, predictions, output_dict=True)\n",
        "    conf_matrix = confusion_matrix(labels, predictions)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(labels, predictions, digits=4))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1_per_class\": f1.tolist(),\n",
        "        \"precision_per_class\": precision.tolist(),\n",
        "        \"recall_per_class\": recall.tolist(),\n",
        "        \"confusion_matrix\": conf_matrix.tolist(),\n",
        "        \"report\": report,\n",
        "    }\n",
        "\n",
        "def train_rag_model(model, train_df, retrieval_model, faiss_index, headlines, period_name, eval_dataset):\n",
        "    print(f\"\\nTraining RAG model for {period_name}...\")\n",
        "    train_dataset = FakeNewsDataset(train_df, tokenizer, retrieval_model, faiss_index, headlines, max_length=512)\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=rag_training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=eval_dataset,\n",
        "        compute_metrics=compute_metrics_rag,\n",
        "    )\n",
        "    trainer.train()\n",
        "    results = trainer.evaluate()\n",
        "    print(f\"{period_name} RAG Model Test Accuracy after training: {results['eval_accuracy']:.4f}\")\n",
        "    return model\n",
        "\n",
        "def evaluate_rag_on_period(model, period_name, df_period, retrieval_model, faiss_index, headlines):\n",
        "    print(f\"\\nEvaluating RAG model on {period_name}...\")\n",
        "    dataset = FakeNewsDataset(df_period, tokenizer, retrieval_model, faiss_index, headlines, max_length=512)\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=rag_training_args,\n",
        "        eval_dataset=dataset,\n",
        "        compute_metrics=compute_metrics_rag,\n",
        "    )\n",
        "    results = trainer.evaluate()\n",
        "    preds = trainer.predict(dataset).predictions\n",
        "    pred_labels = np.argmax(preds, axis=1)\n",
        "    true_labels = [item[\"labels\"].item() for item in dataset]\n",
        "    report = classification_report(true_labels, pred_labels, target_names=[\"Fake\", \"Real\"])\n",
        "    print(f\"{period_name} RAG Model Accuracy: {results['eval_accuracy']:.4f}\")\n",
        "    print(report)\n",
        "    return results, report\n",
        "\n",
        "def rolling_evaluation_RAG(model, model_version, retrieval_model):\n",
        "    mapping = {\n",
        "        \"Baseline\": [(\"Update 1\", update1_df, index_update1, headlines_update1),\n",
        "                     (\"Update 2\", update2_df, index_update2, headlines_update2),\n",
        "                     (\"Update 3\", update3_df, index_update3, headlines_update3),\n",
        "                     (\"Update 4\", update4_df, index_update4, headlines_update4),\n",
        "                     (\"Test\", test_df, index_update4, headlines_update4)],\n",
        "        \"Update 1\": [(\"Update 1\", update1_df, index_update1, headlines_update1),\n",
        "                     (\"Update 2\", update2_df, index_update2, headlines_update2),\n",
        "                     (\"Update 3\", update3_df, index_update3, headlines_update3),\n",
        "                     (\"Update 4\", update4_df, index_update4, headlines_update4),\n",
        "                     (\"Test\", test_df, index_update4, headlines_update4)],\n",
        "        \"Update 2\": [(\"Update 2\", update2_df, index_update2, headlines_update2),\n",
        "                     (\"Update 3\", update3_df, index_update3, headlines_update3),\n",
        "                     (\"Update 4\", update4_df, index_update4, headlines_update4),\n",
        "                     (\"Test\", test_df, index_update4, headlines_update4)],\n",
        "        \"Update 3\": [(\"Update 3\", update3_df, index_update3, headlines_update3),\n",
        "                     (\"Update 4\", update4_df, index_update4, headlines_update4),\n",
        "                     (\"Test\", test_df, index_update4, headlines_update4)],\n",
        "        \"Update 4\": [(\"Update 4\", update4_df, index_update4, headlines_update4),\n",
        "                     (\"Test\", test_df, index_update4, headlines_update4)],\n",
        "    }\n",
        "    evaluations = {}\n",
        "    if model_version in mapping:\n",
        "        for period_name, df_period, faiss_idx, headlines_period in mapping[model_version]:\n",
        "            evaluations[period_name] = evaluate_rag_on_period(model, period_name, df_period, retrieval_model, faiss_idx, headlines_period)\n",
        "    else:\n",
        "        print(f\"No rolling evaluation defined for model version: {model_version}\")\n",
        "    return evaluations\n",
        "\n",
        "def save_and_zip_model(model, tokenizer, model_dir):\n",
        "    model.save_pretrained(model_dir)\n",
        "    tokenizer.save_pretrained(model_dir)\n",
        "    print(f\"Model and tokenizer saved to {model_dir}\")\n",
        "    shutil.make_archive(model_dir, 'zip', model_dir)\n",
        "    print(f\"Created {model_dir}.zip\")\n"
      ],
      "metadata": {
        "id": "-XnWiLWVsDCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAG Experiment Runs\n",
        "\n",
        "test_dataset_RAG = FakeNewsDataset(test_df, tokenizer, SentenceTransformer(\"all-MiniLM-L6-v2\"), index_update4, headlines_update4, max_length=512)\n",
        "\n",
        "# Initialize the RAG model (a separate copy from the CL pipeline) and the retrieval model (SentenceTransformer)\n",
        "model_RAG = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "retrieval_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crj8luNNsiQz",
        "outputId": "7072881b-5036-469b-f860-37b73e454fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on Baseline (2007-2015) using baseline FAISS info, then evaluate on all future periods\n",
        "print(\"Training RAG Baseline Model (2007-2015)...\")\n",
        "model_RAG = train_rag_model(model_RAG, baseline_df, retrieval_model, index_baseline, headlines_baseline, \"Baseline (2007-2015)\", test_dataset_RAG)\n",
        "save_and_zip_model(model_RAG, tokenizer, \"fine_tuned_bert_baseline_RAG\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RoO0yw_stPQF",
        "outputId": "2b25f92f-0996-42e1-d71e-5a274ae0affb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RAG Baseline Model (2007-2015)...\n",
            "\n",
            "Training RAG model for Baseline (2007-2015)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2734' max='2734' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2734/2734 47:18, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.679200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.678100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.657900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.671500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.637500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.627400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.596000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.589300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.579000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.554400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:50]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9641    0.8383    0.8968       705\n",
            "           1     0.4124    0.7843    0.5405       102\n",
            "\n",
            "    accuracy                         0.8315       807\n",
            "   macro avg     0.6882    0.8113    0.7187       807\n",
            "weighted avg     0.8944    0.8315    0.8518       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[591 114]\n",
            " [ 22  80]]\n",
            "Baseline (2007-2015) RAG Model Test Accuracy after training: 0.8315\n",
            "Model and tokenizer saved to fine_tuned_bert_baseline_RAG\n",
            "Created fine_tuned_bert_baseline_RAG.zip\n",
            "\n",
            "Rolling Evaluation for RAG Baseline Model:\n",
            "\n",
            "Evaluating RAG model on Update 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6974    0.5441    0.6113      1555\n",
            "           1     0.6100    0.7514    0.6733      1476\n",
            "\n",
            "    accuracy                         0.6450      3031\n",
            "   macro avg     0.6537    0.6477    0.6423      3031\n",
            "weighted avg     0.6549    0.6450    0.6415      3031\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 846  709]\n",
            " [ 367 1109]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6974    0.5441    0.6113      1555\n",
            "           1     0.6100    0.7514    0.6733      1476\n",
            "\n",
            "    accuracy                         0.6450      3031\n",
            "   macro avg     0.6537    0.6477    0.6423      3031\n",
            "weighted avg     0.6549    0.6450    0.6415      3031\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 846  709]\n",
            " [ 367 1109]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Cannot index by location index with a non-integer key",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-b6be8824133c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_and_zip_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_RAG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fine_tuned_bert_baseline_RAG\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nRolling Evaluation for RAG Baseline Model:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrolling_evaluation_RAG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_RAG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Baseline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieval_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-5d941df10ad0>\u001b[0m in \u001b[0;36mrolling_evaluation_RAG\u001b[0;34m(model, model_version, retrieval_model)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_version\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mperiod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadlines_period\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mevaluations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperiod_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_rag_on_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretrieval_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaiss_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadlines_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No rolling evaluation defined for model version: {model_version}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-5d941df10ad0>\u001b[0m in \u001b[0;36mevaluate_rag_on_period\u001b[0;34m(model, period_name, df_period, retrieval_model, faiss_index, headlines)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Fake\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Real\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{period_name} RAG Model Accuracy: {results['eval_accuracy']:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-64aaf67e2c8e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1747\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index by location index with a non-integer key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot index by location index with a non-integer key"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRolling Evaluation for RAG Baseline Model:\")\n",
        "rolling_evaluation_RAG(model_RAG, \"Baseline\", retrieval_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oF9KyvpVIeeZ",
        "outputId": "e1de479b-d7bd-45be-edd4-5df89e920850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rolling Evaluation for RAG Baseline Model:\n",
            "\n",
            "Evaluating RAG model on Update 1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6974    0.5441    0.6113      1555\n",
            "           1     0.6100    0.7514    0.6733      1476\n",
            "\n",
            "    accuracy                         0.6450      3031\n",
            "   macro avg     0.6537    0.6477    0.6423      3031\n",
            "weighted avg     0.6549    0.6450    0.6415      3031\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 846  709]\n",
            " [ 367 1109]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6974    0.5441    0.6113      1555\n",
            "           1     0.6100    0.7514    0.6733      1476\n",
            "\n",
            "    accuracy                         0.6450      3031\n",
            "   macro avg     0.6537    0.6477    0.6423      3031\n",
            "weighted avg     0.6549    0.6450    0.6415      3031\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 846  709]\n",
            " [ 367 1109]]\n",
            "Update 1 RAG Model Accuracy: 0.6450\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.70      0.54      0.61      1555\n",
            "        Real       0.61      0.75      0.67      1476\n",
            "\n",
            "    accuracy                           0.65      3031\n",
            "   macro avg       0.65      0.65      0.64      3031\n",
            "weighted avg       0.65      0.65      0.64      3031\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7993    0.6202    0.6985      1759\n",
            "           1     0.5106    0.7178    0.5967       971\n",
            "\n",
            "    accuracy                         0.6549      2730\n",
            "   macro avg     0.6549    0.6690    0.6476      2730\n",
            "weighted avg     0.6966    0.6549    0.6623      2730\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1091  668]\n",
            " [ 274  697]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7993    0.6202    0.6985      1759\n",
            "           1     0.5106    0.7178    0.5967       971\n",
            "\n",
            "    accuracy                         0.6549      2730\n",
            "   macro avg     0.6549    0.6690    0.6476      2730\n",
            "weighted avg     0.6966    0.6549    0.6623      2730\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1091  668]\n",
            " [ 274  697]]\n",
            "Update 2 RAG Model Accuracy: 0.6549\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.80      0.62      0.70      1759\n",
            "        Real       0.51      0.72      0.60       971\n",
            "\n",
            "    accuracy                           0.65      2730\n",
            "   macro avg       0.65      0.67      0.65      2730\n",
            "weighted avg       0.70      0.65      0.66      2730\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8980    0.7325    0.8069      3006\n",
            "           1     0.3909    0.6736    0.4947       766\n",
            "\n",
            "    accuracy                         0.7206      3772\n",
            "   macro avg     0.6445    0.7031    0.6508      3772\n",
            "weighted avg     0.7951    0.7206    0.7435      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2202  804]\n",
            " [ 250  516]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8980    0.7325    0.8069      3006\n",
            "           1     0.3909    0.6736    0.4947       766\n",
            "\n",
            "    accuracy                         0.7206      3772\n",
            "   macro avg     0.6445    0.7031    0.6508      3772\n",
            "weighted avg     0.7951    0.7206    0.7435      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2202  804]\n",
            " [ 250  516]]\n",
            "Update 3 RAG Model Accuracy: 0.7206\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.90      0.73      0.81      3006\n",
            "        Real       0.39      0.67      0.49       766\n",
            "\n",
            "    accuracy                           0.72      3772\n",
            "   macro avg       0.64      0.70      0.65      3772\n",
            "weighted avg       0.80      0.72      0.74      3772\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9274    0.7610    0.8360      1427\n",
            "           1     0.3404    0.6743    0.4524       261\n",
            "\n",
            "    accuracy                         0.7476      1688\n",
            "   macro avg     0.6339    0.7177    0.6442      1688\n",
            "weighted avg     0.8367    0.7476    0.7767      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1086  341]\n",
            " [  85  176]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9274    0.7610    0.8360      1427\n",
            "           1     0.3404    0.6743    0.4524       261\n",
            "\n",
            "    accuracy                         0.7476      1688\n",
            "   macro avg     0.6339    0.7177    0.6442      1688\n",
            "weighted avg     0.8367    0.7476    0.7767      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1086  341]\n",
            " [  85  176]]\n",
            "Update 4 RAG Model Accuracy: 0.7476\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.76      0.84      1427\n",
            "        Real       0.34      0.67      0.45       261\n",
            "\n",
            "    accuracy                           0.75      1688\n",
            "   macro avg       0.63      0.72      0.64      1688\n",
            "weighted avg       0.84      0.75      0.78      1688\n",
            "\n",
            "\n",
            "Evaluating RAG model on Test...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9641    0.8383    0.8968       705\n",
            "           1     0.4124    0.7843    0.5405       102\n",
            "\n",
            "    accuracy                         0.8315       807\n",
            "   macro avg     0.6882    0.8113    0.7187       807\n",
            "weighted avg     0.8944    0.8315    0.8518       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[591 114]\n",
            " [ 22  80]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9641    0.8383    0.8968       705\n",
            "           1     0.4124    0.7843    0.5405       102\n",
            "\n",
            "    accuracy                         0.8315       807\n",
            "   macro avg     0.6882    0.8113    0.7187       807\n",
            "weighted avg     0.8944    0.8315    0.8518       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[591 114]\n",
            " [ 22  80]]\n",
            "Test RAG Model Accuracy: 0.8315\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.84      0.90       705\n",
            "        Real       0.41      0.78      0.54       102\n",
            "\n",
            "    accuracy                           0.83       807\n",
            "   macro avg       0.69      0.81      0.72       807\n",
            "weighted avg       0.89      0.83      0.85       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 1': ({'eval_loss': 0.6616322994232178,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.6450016496205873,\n",
              "   'eval_f1_per_class': [0.611271676300578, 0.6733454766241651],\n",
              "   'eval_precision_per_class': [0.6974443528441879, 0.61001100110011],\n",
              "   'eval_recall_per_class': [0.5440514469453376, 0.7513550135501355],\n",
              "   'eval_confusion_matrix': [[846, 709], [367, 1109]],\n",
              "   'eval_report': {'0': {'precision': 0.6974443528441879,\n",
              "     'recall': 0.5440514469453376,\n",
              "     'f1-score': 0.611271676300578,\n",
              "     'support': 1555.0},\n",
              "    '1': {'precision': 0.61001100110011,\n",
              "     'recall': 0.7513550135501355,\n",
              "     'f1-score': 0.6733454766241651,\n",
              "     'support': 1476.0},\n",
              "    'accuracy': 0.6450016496205873,\n",
              "    'macro avg': {'precision': 0.653727676972149,\n",
              "     'recall': 0.6477032302477366,\n",
              "     'f1-score': 0.6423085764623715,\n",
              "     'support': 3031.0},\n",
              "    'weighted avg': {'precision': 0.6548671086428487,\n",
              "     'recall': 0.6450016496205873,\n",
              "     'f1-score': 0.6414996305327175,\n",
              "     'support': 3031.0}},\n",
              "   'eval_runtime': 196.9619,\n",
              "   'eval_samples_per_second': 15.389,\n",
              "   'eval_steps_per_second': 1.924},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.70      0.54      0.61      1555\\n        Real       0.61      0.75      0.67      1476\\n\\n    accuracy                           0.65      3031\\n   macro avg       0.65      0.65      0.64      3031\\nweighted avg       0.65      0.65      0.64      3031\\n'),\n",
              " 'Update 2': ({'eval_loss': 0.6445968747138977,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.654945054945055,\n",
              "   'eval_f1_per_class': [0.6984635083226632, 0.5967465753424658],\n",
              "   'eval_precision_per_class': [0.7992673992673993, 0.5106227106227106],\n",
              "   'eval_recall_per_class': [0.6202387720295622, 0.717816683831102],\n",
              "   'eval_confusion_matrix': [[1091, 668], [274, 697]],\n",
              "   'eval_report': {'0': {'precision': 0.7992673992673993,\n",
              "     'recall': 0.6202387720295622,\n",
              "     'f1-score': 0.6984635083226632,\n",
              "     'support': 1759.0},\n",
              "    '1': {'precision': 0.5106227106227106,\n",
              "     'recall': 0.717816683831102,\n",
              "     'f1-score': 0.5967465753424658,\n",
              "     'support': 971.0},\n",
              "    'accuracy': 0.654945054945055,\n",
              "    'macro avg': {'precision': 0.654945054945055,\n",
              "     'recall': 0.669027727930332,\n",
              "     'f1-score': 0.6476050418325645,\n",
              "     'support': 2730.0},\n",
              "    'weighted avg': {'precision': 0.6966029330864496,\n",
              "     'recall': 0.654945054945055,\n",
              "     'f1-score': 0.6622850680575454,\n",
              "     'support': 2730.0}},\n",
              "   'eval_runtime': 174.995,\n",
              "   'eval_samples_per_second': 15.6,\n",
              "   'eval_steps_per_second': 1.954},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.80      0.62      0.70      1759\\n        Real       0.51      0.72      0.60       971\\n\\n    accuracy                           0.65      2730\\n   macro avg       0.65      0.67      0.65      2730\\nweighted avg       0.70      0.65      0.66      2730\\n'),\n",
              " 'Update 3': ({'eval_loss': 0.5556873679161072,\n",
              "   'eval_model_preparation_time': 0.0049,\n",
              "   'eval_accuracy': 0.7205726405090138,\n",
              "   'eval_f1_per_class': [0.8068889703187981, 0.4947267497603068],\n",
              "   'eval_precision_per_class': [0.898042414355628, 0.39090909090909093],\n",
              "   'eval_recall_per_class': [0.7325349301397206, 0.6736292428198434],\n",
              "   'eval_confusion_matrix': [[2202, 804], [250, 516]],\n",
              "   'eval_report': {'0': {'precision': 0.898042414355628,\n",
              "     'recall': 0.7325349301397206,\n",
              "     'f1-score': 0.8068889703187981,\n",
              "     'support': 3006.0},\n",
              "    '1': {'precision': 0.39090909090909093,\n",
              "     'recall': 0.6736292428198434,\n",
              "     'f1-score': 0.4947267497603068,\n",
              "     'support': 766.0},\n",
              "    'accuracy': 0.7205726405090138,\n",
              "    'macro avg': {'precision': 0.6444757526323595,\n",
              "     'recall': 0.703082086479782,\n",
              "     'f1-score': 0.6508078600395525,\n",
              "     'support': 3772.0},\n",
              "    'weighted avg': {'precision': 0.7950561668052443,\n",
              "     'recall': 0.7205726405090138,\n",
              "     'f1-score': 0.7434965363453611,\n",
              "     'support': 3772.0}},\n",
              "   'eval_runtime': 240.5483,\n",
              "   'eval_samples_per_second': 15.681,\n",
              "   'eval_steps_per_second': 1.962},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.90      0.73      0.81      3006\\n        Real       0.39      0.67      0.49       766\\n\\n    accuracy                           0.72      3772\\n   macro avg       0.64      0.70      0.65      3772\\nweighted avg       0.80      0.72      0.74      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.5250164270401001,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.7476303317535545,\n",
              "   'eval_f1_per_class': [0.836027713625866, 0.4524421593830334],\n",
              "   'eval_precision_per_class': [0.9274124679760888, 0.3404255319148936],\n",
              "   'eval_recall_per_class': [0.7610371408549405, 0.6743295019157088],\n",
              "   'eval_confusion_matrix': [[1086, 341], [85, 176]],\n",
              "   'eval_report': {'0': {'precision': 0.9274124679760888,\n",
              "     'recall': 0.7610371408549405,\n",
              "     'f1-score': 0.836027713625866,\n",
              "     'support': 1427.0},\n",
              "    '1': {'precision': 0.3404255319148936,\n",
              "     'recall': 0.6743295019157088,\n",
              "     'f1-score': 0.4524421593830334,\n",
              "     'support': 261.0},\n",
              "    'accuracy': 0.7476303317535545,\n",
              "    'macro avg': {'precision': 0.6339189999454912,\n",
              "     'recall': 0.7176833213853246,\n",
              "     'f1-score': 0.6442349365044497,\n",
              "     'support': 1688.0},\n",
              "    'weighted avg': {'precision': 0.8366520471751576,\n",
              "     'recall': 0.7476303317535545,\n",
              "     'f1-score': 0.7767173879994564,\n",
              "     'support': 1688.0}},\n",
              "   'eval_runtime': 107.2407,\n",
              "   'eval_samples_per_second': 15.74,\n",
              "   'eval_steps_per_second': 1.968},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.93      0.76      0.84      1427\\n        Real       0.34      0.67      0.45       261\\n\\n    accuracy                           0.75      1688\\n   macro avg       0.63      0.72      0.64      1688\\nweighted avg       0.84      0.75      0.78      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.4068746864795685,\n",
              "   'eval_model_preparation_time': 0.0051,\n",
              "   'eval_accuracy': 0.8314745972738538,\n",
              "   'eval_f1_per_class': [0.8968133535660091, 0.5405405405405406],\n",
              "   'eval_precision_per_class': [0.964110929853181, 0.41237113402061853],\n",
              "   'eval_recall_per_class': [0.8382978723404255, 0.7843137254901961],\n",
              "   'eval_confusion_matrix': [[591, 114], [22, 80]],\n",
              "   'eval_report': {'0': {'precision': 0.964110929853181,\n",
              "     'recall': 0.8382978723404255,\n",
              "     'f1-score': 0.8968133535660091,\n",
              "     'support': 705.0},\n",
              "    '1': {'precision': 0.41237113402061853,\n",
              "     'recall': 0.7843137254901961,\n",
              "     'f1-score': 0.5405405405405406,\n",
              "     'support': 102.0},\n",
              "    'accuracy': 0.8314745972738538,\n",
              "    'macro avg': {'precision': 0.6882410319368998,\n",
              "     'recall': 0.8113057989153107,\n",
              "     'f1-score': 0.7186769470532748,\n",
              "     'support': 807.0},\n",
              "    'weighted avg': {'precision': 0.8943743013836379,\n",
              "     'recall': 0.8314745972738538,\n",
              "     'f1-score': 0.8517825890943885,\n",
              "     'support': 807.0}},\n",
              "   'eval_runtime': 51.5917,\n",
              "   'eval_samples_per_second': 15.642,\n",
              "   'eval_steps_per_second': 1.958},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.96      0.84      0.90       705\\n        Real       0.41      0.78      0.54       102\\n\\n    accuracy                           0.83       807\\n   macro avg       0.69      0.81      0.72       807\\nweighted avg       0.89      0.83      0.85       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 1 (2016-2017)\n",
        "print(\"\\nTraining RAG Update 1 Model (2016-2017)...\")\n",
        "model_RAG = train_rag_model(model_RAG, update1_df, retrieval_model, index_update1, headlines_update1, \"Update 1 (2016-2017)\", test_dataset_RAG)\n",
        "save_and_zip_model(model_RAG, tokenizer, \"fine_tuned_bert_update_1_RAG\")\n",
        "print(\"\\nRolling Evaluation for RAG Update 1 Model:\")\n",
        "rolling_evaluation_RAG(model_RAG, \"Update 1\", retrieval_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WhxzjLvttVqi",
        "outputId": "4e7938fe-fbb0-4d81-a1ad-cf44d85ab19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training RAG Update 1 Model (2016-2017)...\n",
            "\n",
            "Training RAG model for Update 1 (2016-2017)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='758' max='758' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [758/758 13:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.631700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.531100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.471400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:50]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9587    0.8227    0.8855       705\n",
            "           1     0.3812    0.7549    0.5066       102\n",
            "\n",
            "    accuracy                         0.8141       807\n",
            "   macro avg     0.6699    0.7888    0.6960       807\n",
            "weighted avg     0.8857    0.8141    0.8376       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[580 125]\n",
            " [ 25  77]]\n",
            "Update 1 (2016-2017) RAG Model Test Accuracy after training: 0.8141\n",
            "Model and tokenizer saved to fine_tuned_bert_update_1_RAG\n",
            "Created fine_tuned_bert_update_1_RAG.zip\n",
            "\n",
            "Rolling Evaluation for RAG Update 1 Model:\n",
            "\n",
            "Evaluating RAG model on Update 1...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='428' max='379' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [379/379 03:37]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9295    0.7627    0.8379      1555\n",
            "           1     0.7897    0.9390    0.8579      1476\n",
            "\n",
            "    accuracy                         0.8486      3031\n",
            "   macro avg     0.8596    0.8509    0.8479      3031\n",
            "weighted avg     0.8614    0.8486    0.8476      3031\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1186  369]\n",
            " [  90 1386]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9295    0.7627    0.8379      1555\n",
            "           1     0.7897    0.9390    0.8579      1476\n",
            "\n",
            "    accuracy                         0.8486      3031\n",
            "   macro avg     0.8596    0.8509    0.8479      3031\n",
            "weighted avg     0.8614    0.8486    0.8476      3031\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1186  369]\n",
            " [  90 1386]]\n",
            "Update 1 RAG Model Accuracy: 0.8486\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.76      0.84      1555\n",
            "        Real       0.79      0.94      0.86      1476\n",
            "\n",
            "    accuracy                           0.85      3031\n",
            "   macro avg       0.86      0.85      0.85      3031\n",
            "weighted avg       0.86      0.85      0.85      3031\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8191    0.6333    0.7143      1759\n",
            "           1     0.5292    0.7467    0.6194       971\n",
            "\n",
            "    accuracy                         0.6736      2730\n",
            "   macro avg     0.6742    0.6900    0.6669      2730\n",
            "weighted avg     0.7160    0.6736    0.6806      2730\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1114  645]\n",
            " [ 246  725]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8191    0.6333    0.7143      1759\n",
            "           1     0.5292    0.7467    0.6194       971\n",
            "\n",
            "    accuracy                         0.6736      2730\n",
            "   macro avg     0.6742    0.6900    0.6669      2730\n",
            "weighted avg     0.7160    0.6736    0.6806      2730\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1114  645]\n",
            " [ 246  725]]\n",
            "Update 2 RAG Model Accuracy: 0.6736\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.82      0.63      0.71      1759\n",
            "        Real       0.53      0.75      0.62       971\n",
            "\n",
            "    accuracy                           0.67      2730\n",
            "   macro avg       0.67      0.69      0.67      2730\n",
            "weighted avg       0.72      0.67      0.68      2730\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9008    0.7552    0.8216      3006\n",
            "           1     0.4121    0.6736    0.5114       766\n",
            "\n",
            "    accuracy                         0.7386      3772\n",
            "   macro avg     0.6565    0.7144    0.6665      3772\n",
            "weighted avg     0.8016    0.7386    0.7586      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2270  736]\n",
            " [ 250  516]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9008    0.7552    0.8216      3006\n",
            "           1     0.4121    0.6736    0.5114       766\n",
            "\n",
            "    accuracy                         0.7386      3772\n",
            "   macro avg     0.6565    0.7144    0.6665      3772\n",
            "weighted avg     0.8016    0.7386    0.7586      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2270  736]\n",
            " [ 250  516]]\n",
            "Update 3 RAG Model Accuracy: 0.7386\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.90      0.76      0.82      3006\n",
            "        Real       0.41      0.67      0.51       766\n",
            "\n",
            "    accuracy                           0.74      3772\n",
            "   macro avg       0.66      0.71      0.67      3772\n",
            "weighted avg       0.80      0.74      0.76      3772\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9406    0.7540    0.8370      1427\n",
            "           1     0.3548    0.7395    0.4795       261\n",
            "\n",
            "    accuracy                         0.7518      1688\n",
            "   macro avg     0.6477    0.7467    0.6583      1688\n",
            "weighted avg     0.8500    0.7518    0.7817      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1076  351]\n",
            " [  68  193]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9406    0.7540    0.8370      1427\n",
            "           1     0.3548    0.7395    0.4795       261\n",
            "\n",
            "    accuracy                         0.7518      1688\n",
            "   macro avg     0.6477    0.7467    0.6583      1688\n",
            "weighted avg     0.8500    0.7518    0.7817      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1076  351]\n",
            " [  68  193]]\n",
            "Update 4 RAG Model Accuracy: 0.7518\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.94      0.75      0.84      1427\n",
            "        Real       0.35      0.74      0.48       261\n",
            "\n",
            "    accuracy                           0.75      1688\n",
            "   macro avg       0.65      0.75      0.66      1688\n",
            "weighted avg       0.85      0.75      0.78      1688\n",
            "\n",
            "\n",
            "Evaluating RAG model on Test...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9587    0.8227    0.8855       705\n",
            "           1     0.3812    0.7549    0.5066       102\n",
            "\n",
            "    accuracy                         0.8141       807\n",
            "   macro avg     0.6699    0.7888    0.6960       807\n",
            "weighted avg     0.8857    0.8141    0.8376       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[580 125]\n",
            " [ 25  77]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9587    0.8227    0.8855       705\n",
            "           1     0.3812    0.7549    0.5066       102\n",
            "\n",
            "    accuracy                         0.8141       807\n",
            "   macro avg     0.6699    0.7888    0.6960       807\n",
            "weighted avg     0.8857    0.8141    0.8376       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[580 125]\n",
            " [ 25  77]]\n",
            "Test RAG Model Accuracy: 0.8141\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.96      0.82      0.89       705\n",
            "        Real       0.38      0.75      0.51       102\n",
            "\n",
            "    accuracy                           0.81       807\n",
            "   macro avg       0.67      0.79      0.70       807\n",
            "weighted avg       0.89      0.81      0.84       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 1': ({'eval_loss': 0.3466470241546631,\n",
              "   'eval_model_preparation_time': 0.0031,\n",
              "   'eval_accuracy': 0.8485648300890795,\n",
              "   'eval_f1_per_class': [0.8378664782762275, 0.8579387186629527],\n",
              "   'eval_precision_per_class': [0.9294670846394985, 0.7897435897435897],\n",
              "   'eval_recall_per_class': [0.7627009646302251, 0.9390243902439024],\n",
              "   'eval_confusion_matrix': [[1186, 369], [90, 1386]],\n",
              "   'eval_report': {'0': {'precision': 0.9294670846394985,\n",
              "     'recall': 0.7627009646302251,\n",
              "     'f1-score': 0.8378664782762275,\n",
              "     'support': 1555.0},\n",
              "    '1': {'precision': 0.7897435897435897,\n",
              "     'recall': 0.9390243902439024,\n",
              "     'f1-score': 0.8579387186629527,\n",
              "     'support': 1476.0},\n",
              "    'accuracy': 0.8485648300890795,\n",
              "    'macro avg': {'precision': 0.8596053371915441,\n",
              "     'recall': 0.8508626774370638,\n",
              "     'f1-score': 0.84790259846959,\n",
              "     'support': 3031.0},\n",
              "    'weighted avg': {'precision': 0.8614262141458128,\n",
              "     'recall': 0.8485648300890795,\n",
              "     'f1-score': 0.8476410169798918,\n",
              "     'support': 3031.0}},\n",
              "   'eval_runtime': 193.1328,\n",
              "   'eval_samples_per_second': 15.694,\n",
              "   'eval_steps_per_second': 1.962},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.93      0.76      0.84      1555\\n        Real       0.79      0.94      0.86      1476\\n\\n    accuracy                           0.85      3031\\n   macro avg       0.86      0.85      0.85      3031\\nweighted avg       0.86      0.85      0.85      3031\\n'),\n",
              " 'Update 2': ({'eval_loss': 0.6625968217849731,\n",
              "   'eval_model_preparation_time': 0.004,\n",
              "   'eval_accuracy': 0.6736263736263737,\n",
              "   'eval_f1_per_class': [0.7143315165117025, 0.6193934216146946],\n",
              "   'eval_precision_per_class': [0.8191176470588235, 0.5291970802919708],\n",
              "   'eval_recall_per_class': [0.633314383172257, 0.7466529351184346],\n",
              "   'eval_confusion_matrix': [[1114, 645], [246, 725]],\n",
              "   'eval_report': {'0': {'precision': 0.8191176470588235,\n",
              "     'recall': 0.633314383172257,\n",
              "     'f1-score': 0.7143315165117025,\n",
              "     'support': 1759.0},\n",
              "    '1': {'precision': 0.5291970802919708,\n",
              "     'recall': 0.7466529351184346,\n",
              "     'f1-score': 0.6193934216146946,\n",
              "     'support': 971.0},\n",
              "    'accuracy': 0.6736263736263737,\n",
              "    'macro avg': {'precision': 0.6741573636753971,\n",
              "     'recall': 0.6899836591453458,\n",
              "     'f1-score': 0.6668624690631986,\n",
              "     'support': 2730.0},\n",
              "    'weighted avg': {'precision': 0.715999379538452,\n",
              "     'recall': 0.6736263736263737,\n",
              "     'f1-score': 0.6805641574842318,\n",
              "     'support': 2730.0}},\n",
              "   'eval_runtime': 173.1747,\n",
              "   'eval_samples_per_second': 15.764,\n",
              "   'eval_steps_per_second': 1.975},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.82      0.63      0.71      1759\\n        Real       0.53      0.75      0.62       971\\n\\n    accuracy                           0.67      2730\\n   macro avg       0.67      0.69      0.67      2730\\nweighted avg       0.72      0.67      0.68      2730\\n'),\n",
              " 'Update 3': ({'eval_loss': 0.5310490727424622,\n",
              "   'eval_model_preparation_time': 0.0047,\n",
              "   'eval_accuracy': 0.7386002120890774,\n",
              "   'eval_f1_per_class': [0.8215707564241767, 0.5113974231912785],\n",
              "   'eval_precision_per_class': [0.9007936507936508, 0.41214057507987223],\n",
              "   'eval_recall_per_class': [0.7551563539587491, 0.6736292428198434],\n",
              "   'eval_confusion_matrix': [[2270, 736], [250, 516]],\n",
              "   'eval_report': {'0': {'precision': 0.9007936507936508,\n",
              "     'recall': 0.7551563539587491,\n",
              "     'f1-score': 0.8215707564241767,\n",
              "     'support': 3006.0},\n",
              "    '1': {'precision': 0.41214057507987223,\n",
              "     'recall': 0.6736292428198434,\n",
              "     'f1-score': 0.5113974231912785,\n",
              "     'support': 766.0},\n",
              "    'accuracy': 0.7386002120890774,\n",
              "    'macro avg': {'precision': 0.6564671129367615,\n",
              "     'recall': 0.7143927983892963,\n",
              "     'f1-score': 0.6664840898077276,\n",
              "     'support': 3772.0},\n",
              "    'weighted avg': {'precision': 0.8015602849408527,\n",
              "     'recall': 0.7386002120890774,\n",
              "     'f1-score': 0.7585822163243888,\n",
              "     'support': 3772.0}},\n",
              "   'eval_runtime': 243.4686,\n",
              "   'eval_samples_per_second': 15.493,\n",
              "   'eval_steps_per_second': 1.939},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.90      0.76      0.82      3006\\n        Real       0.41      0.67      0.51       766\\n\\n    accuracy                           0.74      3772\\n   macro avg       0.66      0.71      0.67      3772\\nweighted avg       0.80      0.74      0.76      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.48005807399749756,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.7517772511848341,\n",
              "   'eval_f1_per_class': [0.8370283936211591, 0.4795031055900621],\n",
              "   'eval_precision_per_class': [0.9405594405594405, 0.3547794117647059],\n",
              "   'eval_recall_per_class': [0.7540294323756132, 0.7394636015325671],\n",
              "   'eval_confusion_matrix': [[1076, 351], [68, 193]],\n",
              "   'eval_report': {'0': {'precision': 0.9405594405594405,\n",
              "     'recall': 0.7540294323756132,\n",
              "     'f1-score': 0.8370283936211591,\n",
              "     'support': 1427.0},\n",
              "    '1': {'precision': 0.3547794117647059,\n",
              "     'recall': 0.7394636015325671,\n",
              "     'f1-score': 0.4795031055900621,\n",
              "     'support': 261.0},\n",
              "    'accuracy': 0.7517772511848341,\n",
              "    'macro avg': {'precision': 0.6476694261620732,\n",
              "     'recall': 0.7467465169540901,\n",
              "     'f1-score': 0.6582657496056106,\n",
              "     'support': 1688.0},\n",
              "    'weighted avg': {'precision': 0.8499856327896387,\n",
              "     'recall': 0.7517772511848341,\n",
              "     'f1-score': 0.7817475285879147,\n",
              "     'support': 1688.0}},\n",
              "   'eval_runtime': 106.6388,\n",
              "   'eval_samples_per_second': 15.829,\n",
              "   'eval_steps_per_second': 1.979},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.94      0.75      0.84      1427\\n        Real       0.35      0.74      0.48       261\\n\\n    accuracy                           0.75      1688\\n   macro avg       0.65      0.75      0.66      1688\\nweighted avg       0.85      0.75      0.78      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.3666890859603882,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.8141263940520446,\n",
              "   'eval_f1_per_class': [0.8854961832061069, 0.506578947368421],\n",
              "   'eval_precision_per_class': [0.9586776859504132, 0.3811881188118812],\n",
              "   'eval_recall_per_class': [0.8226950354609929, 0.7549019607843137],\n",
              "   'eval_confusion_matrix': [[580, 125], [25, 77]],\n",
              "   'eval_report': {'0': {'precision': 0.9586776859504132,\n",
              "     'recall': 0.8226950354609929,\n",
              "     'f1-score': 0.8854961832061069,\n",
              "     'support': 705.0},\n",
              "    '1': {'precision': 0.3811881188118812,\n",
              "     'recall': 0.7549019607843137,\n",
              "     'f1-score': 0.506578947368421,\n",
              "     'support': 102.0},\n",
              "    'accuracy': 0.8141263940520446,\n",
              "    'macro avg': {'precision': 0.6699329023811472,\n",
              "     'recall': 0.7887984981226532,\n",
              "     'f1-score': 0.6960375652872639,\n",
              "     'support': 807.0},\n",
              "    'weighted avg': {'precision': 0.8856864395462865,\n",
              "     'recall': 0.8141263940520446,\n",
              "     'f1-score': 0.8376032983790388,\n",
              "     'support': 807.0}},\n",
              "   'eval_runtime': 51.7665,\n",
              "   'eval_samples_per_second': 15.589,\n",
              "   'eval_steps_per_second': 1.951},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.96      0.82      0.89       705\\n        Real       0.38      0.75      0.51       102\\n\\n    accuracy                           0.81       807\\n   macro avg       0.67      0.79      0.70       807\\nweighted avg       0.89      0.81      0.84       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 2 (2018-2019)\n",
        "print(\"\\nTraining RAG Update 2 Model (2018-2019)...\")\n",
        "model_RAG = train_rag_model(model_RAG, update2_df, retrieval_model, index_update2, headlines_update2, \"Update 2 (2018-2019)\", test_dataset_RAG)\n",
        "save_and_zip_model(model_RAG, tokenizer, \"fine_tuned_bert_update_2_RAG\")\n",
        "print(\"\\nRolling Evaluation for RAG Update 2 Model:\")\n",
        "rolling_evaluation_RAG(model_RAG, \"Update 2\", retrieval_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Nx1RDnGntY0G",
        "outputId": "ef3dcc18-f663-413c-dfc4-706376fbec43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training RAG Update 2 Model (2018-2019)...\n",
            "\n",
            "Training RAG model for Update 2 (2018-2019)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='684' max='684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [684/684 12:05, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.571600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.466200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:50]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9476    0.9234    0.9353       705\n",
            "           1     0.5500    0.6471    0.5946       102\n",
            "\n",
            "    accuracy                         0.8885       807\n",
            "   macro avg     0.7488    0.7852    0.7650       807\n",
            "weighted avg     0.8973    0.8885    0.8923       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[651  54]\n",
            " [ 36  66]]\n",
            "Update 2 (2018-2019) RAG Model Test Accuracy after training: 0.8885\n",
            "Model and tokenizer saved to fine_tuned_bert_update_2_RAG\n",
            "Created fine_tuned_bert_update_2_RAG.zip\n",
            "\n",
            "Rolling Evaluation for RAG Update 2 Model:\n",
            "\n",
            "Evaluating RAG model on Update 2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9313    0.8783    0.9040      1759\n",
            "           1     0.8002    0.8826    0.8394       971\n",
            "\n",
            "    accuracy                         0.8799      2730\n",
            "   macro avg     0.8657    0.8805    0.8717      2730\n",
            "weighted avg     0.8847    0.8799    0.8810      2730\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1545  214]\n",
            " [ 114  857]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9313    0.8783    0.9040      1759\n",
            "           1     0.8002    0.8826    0.8394       971\n",
            "\n",
            "    accuracy                         0.8799      2730\n",
            "   macro avg     0.8657    0.8805    0.8717      2730\n",
            "weighted avg     0.8847    0.8799    0.8810      2730\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1545  214]\n",
            " [ 114  857]]\n",
            "Update 2 RAG Model Accuracy: 0.8799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.88      0.90      1759\n",
            "        Real       0.80      0.88      0.84       971\n",
            "\n",
            "    accuracy                           0.88      2730\n",
            "   macro avg       0.87      0.88      0.87      2730\n",
            "weighted avg       0.88      0.88      0.88      2730\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8772    0.8599    0.8685      3006\n",
            "           1     0.4897    0.5274    0.5079       766\n",
            "\n",
            "    accuracy                         0.7924      3772\n",
            "   macro avg     0.6834    0.6937    0.6882      3772\n",
            "weighted avg     0.7985    0.7924    0.7952      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2585  421]\n",
            " [ 362  404]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8772    0.8599    0.8685      3006\n",
            "           1     0.4897    0.5274    0.5079       766\n",
            "\n",
            "    accuracy                         0.7924      3772\n",
            "   macro avg     0.6834    0.6937    0.6882      3772\n",
            "weighted avg     0.7985    0.7924    0.7952      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2585  421]\n",
            " [ 362  404]]\n",
            "Update 3 RAG Model Accuracy: 0.7924\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.88      0.86      0.87      3006\n",
            "        Real       0.49      0.53      0.51       766\n",
            "\n",
            "    accuracy                           0.79      3772\n",
            "   macro avg       0.68      0.69      0.69      3772\n",
            "weighted avg       0.80      0.79      0.80      3772\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9230    0.8655    0.8933      1427\n",
            "           1     0.4514    0.6054    0.5172       261\n",
            "\n",
            "    accuracy                         0.8252      1688\n",
            "   macro avg     0.6872    0.7354    0.7052      1688\n",
            "weighted avg     0.8501    0.8252    0.8352      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1235  192]\n",
            " [ 103  158]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9230    0.8655    0.8933      1427\n",
            "           1     0.4514    0.6054    0.5172       261\n",
            "\n",
            "    accuracy                         0.8252      1688\n",
            "   macro avg     0.6872    0.7354    0.7052      1688\n",
            "weighted avg     0.8501    0.8252    0.8352      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1235  192]\n",
            " [ 103  158]]\n",
            "Update 4 RAG Model Accuracy: 0.8252\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.92      0.87      0.89      1427\n",
            "        Real       0.45      0.61      0.52       261\n",
            "\n",
            "    accuracy                           0.83      1688\n",
            "   macro avg       0.69      0.74      0.71      1688\n",
            "weighted avg       0.85      0.83      0.84      1688\n",
            "\n",
            "\n",
            "Evaluating RAG model on Test...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9476    0.9234    0.9353       705\n",
            "           1     0.5500    0.6471    0.5946       102\n",
            "\n",
            "    accuracy                         0.8885       807\n",
            "   macro avg     0.7488    0.7852    0.7650       807\n",
            "weighted avg     0.8973    0.8885    0.8923       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[651  54]\n",
            " [ 36  66]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9476    0.9234    0.9353       705\n",
            "           1     0.5500    0.6471    0.5946       102\n",
            "\n",
            "    accuracy                         0.8885       807\n",
            "   macro avg     0.7488    0.7852    0.7650       807\n",
            "weighted avg     0.8973    0.8885    0.8923       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[651  54]\n",
            " [ 36  66]]\n",
            "Test RAG Model Accuracy: 0.8885\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.95      0.92      0.94       705\n",
            "        Real       0.55      0.65      0.59       102\n",
            "\n",
            "    accuracy                           0.89       807\n",
            "   macro avg       0.75      0.79      0.76       807\n",
            "weighted avg       0.90      0.89      0.89       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 2': ({'eval_loss': 0.2869799733161926,\n",
              "   'eval_model_preparation_time': 0.0027,\n",
              "   'eval_accuracy': 0.8798534798534798,\n",
              "   'eval_f1_per_class': [0.9040374488004681, 0.8393731635651323],\n",
              "   'eval_precision_per_class': [0.9312839059674503, 0.800186741363212],\n",
              "   'eval_recall_per_class': [0.8783399658897101, 0.88259526261586],\n",
              "   'eval_confusion_matrix': [[1545, 214], [114, 857]],\n",
              "   'eval_report': {'0': {'precision': 0.9312839059674503,\n",
              "     'recall': 0.8783399658897101,\n",
              "     'f1-score': 0.9040374488004681,\n",
              "     'support': 1759.0},\n",
              "    '1': {'precision': 0.800186741363212,\n",
              "     'recall': 0.88259526261586,\n",
              "     'f1-score': 0.8393731635651323,\n",
              "     'support': 971.0},\n",
              "    'accuracy': 0.8798534798534798,\n",
              "    'macro avg': {'precision': 0.8657353236653311,\n",
              "     'recall': 0.880467614252785,\n",
              "     'f1-score': 0.8717053061828002,\n",
              "     'support': 2730.0},\n",
              "    'weighted avg': {'precision': 0.884655573795027,\n",
              "     'recall': 0.8798534798534798,\n",
              "     'f1-score': 0.8810378074218926,\n",
              "     'support': 2730.0}},\n",
              "   'eval_runtime': 173.7853,\n",
              "   'eval_samples_per_second': 15.709,\n",
              "   'eval_steps_per_second': 1.968},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.93      0.88      0.90      1759\\n        Real       0.80      0.88      0.84       971\\n\\n    accuracy                           0.88      2730\\n   macro avg       0.87      0.88      0.87      2730\\nweighted avg       0.88      0.88      0.88      2730\\n'),\n",
              " 'Update 3': ({'eval_loss': 0.4607442021369934,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.7924178154825027,\n",
              "   'eval_f1_per_class': [0.868469679153368, 0.5078566939032055],\n",
              "   'eval_precision_per_class': [0.8771632168306752, 0.4896969696969697],\n",
              "   'eval_recall_per_class': [0.8599467731204258, 0.5274151436031331],\n",
              "   'eval_confusion_matrix': [[2585, 421], [362, 404]],\n",
              "   'eval_report': {'0': {'precision': 0.8771632168306752,\n",
              "     'recall': 0.8599467731204258,\n",
              "     'f1-score': 0.868469679153368,\n",
              "     'support': 3006.0},\n",
              "    '1': {'precision': 0.4896969696969697,\n",
              "     'recall': 0.5274151436031331,\n",
              "     'f1-score': 0.5078566939032055,\n",
              "     'support': 766.0},\n",
              "    'accuracy': 0.7924178154825027,\n",
              "    'macro avg': {'precision': 0.6834300932638224,\n",
              "     'recall': 0.6936809583617795,\n",
              "     'f1-score': 0.6881631865282868,\n",
              "     'support': 3772.0},\n",
              "    'weighted avg': {'precision': 0.7984783957001296,\n",
              "     'recall': 0.7924178154825027,\n",
              "     'f1-score': 0.7952380920108376,\n",
              "     'support': 3772.0}},\n",
              "   'eval_runtime': 239.2402,\n",
              "   'eval_samples_per_second': 15.767,\n",
              "   'eval_steps_per_second': 1.973},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.88      0.86      0.87      3006\\n        Real       0.49      0.53      0.51       766\\n\\n    accuracy                           0.79      3772\\n   macro avg       0.68      0.69      0.69      3772\\nweighted avg       0.80      0.79      0.80      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.37907105684280396,\n",
              "   'eval_model_preparation_time': 0.0029,\n",
              "   'eval_accuracy': 0.8252369668246445,\n",
              "   'eval_f1_per_class': [0.8933092224231465, 0.5171849427168577],\n",
              "   'eval_precision_per_class': [0.9230194319880418, 0.4514285714285714],\n",
              "   'eval_recall_per_class': [0.8654519971969166, 0.6053639846743295],\n",
              "   'eval_confusion_matrix': [[1235, 192], [103, 158]],\n",
              "   'eval_report': {'0': {'precision': 0.9230194319880418,\n",
              "     'recall': 0.8654519971969166,\n",
              "     'f1-score': 0.8933092224231465,\n",
              "     'support': 1427.0},\n",
              "    '1': {'precision': 0.4514285714285714,\n",
              "     'recall': 0.6053639846743295,\n",
              "     'f1-score': 0.5171849427168577,\n",
              "     'support': 261.0},\n",
              "    'accuracy': 0.8252369668246445,\n",
              "    'macro avg': {'precision': 0.6872240017083067,\n",
              "     'recall': 0.735407990935623,\n",
              "     'f1-score': 0.7052470825700021,\n",
              "     'support': 1688.0},\n",
              "    'weighted avg': {'precision': 0.850101650823337,\n",
              "     'recall': 0.8252369668246445,\n",
              "     'f1-score': 0.8351525654306456,\n",
              "     'support': 1688.0}},\n",
              "   'eval_runtime': 106.8221,\n",
              "   'eval_samples_per_second': 15.802,\n",
              "   'eval_steps_per_second': 1.975},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.92      0.87      0.89      1427\\n        Real       0.45      0.61      0.52       261\\n\\n    accuracy                           0.83      1688\\n   macro avg       0.69      0.74      0.71      1688\\nweighted avg       0.85      0.83      0.84      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.2685275673866272,\n",
              "   'eval_model_preparation_time': 0.0045,\n",
              "   'eval_accuracy': 0.8884758364312267,\n",
              "   'eval_f1_per_class': [0.9353448275862069, 0.5945945945945946],\n",
              "   'eval_precision_per_class': [0.9475982532751092, 0.55],\n",
              "   'eval_recall_per_class': [0.9234042553191489, 0.6470588235294118],\n",
              "   'eval_confusion_matrix': [[651, 54], [36, 66]],\n",
              "   'eval_report': {'0': {'precision': 0.9475982532751092,\n",
              "     'recall': 0.9234042553191489,\n",
              "     'f1-score': 0.9353448275862069,\n",
              "     'support': 705.0},\n",
              "    '1': {'precision': 0.55,\n",
              "     'recall': 0.6470588235294118,\n",
              "     'f1-score': 0.5945945945945946,\n",
              "     'support': 102.0},\n",
              "    'accuracy': 0.8884758364312267,\n",
              "    'macro avg': {'precision': 0.7487991266375547,\n",
              "     'recall': 0.7852315394242804,\n",
              "     'f1-score': 0.7649697110904008,\n",
              "     'support': 807.0},\n",
              "    'weighted avg': {'precision': 0.8973441989578091,\n",
              "     'recall': 0.8884758364312267,\n",
              "     'f1-score': 0.8922760249032521,\n",
              "     'support': 807.0}},\n",
              "   'eval_runtime': 51.5639,\n",
              "   'eval_samples_per_second': 15.65,\n",
              "   'eval_steps_per_second': 1.959},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.95      0.92      0.94       705\\n        Real       0.55      0.65      0.59       102\\n\\n    accuracy                           0.89       807\\n   macro avg       0.75      0.79      0.76       807\\nweighted avg       0.90      0.89      0.89       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 3 (2020-2021)\n",
        "print(\"\\nTraining RAG Update 3 Model (2020-2021)...\")\n",
        "model_RAG = train_rag_model(model_RAG, update3_df, retrieval_model, index_update3, headlines_update3, \"Update 3 (2020-2021)\", test_dataset_RAG)\n",
        "save_and_zip_model(model_RAG, tokenizer, \"fine_tuned_bert_update_3_RAG\")\n",
        "print(\"\\nRolling Evaluation for RAG Update 3 Model:\")\n",
        "rolling_evaluation_RAG(model_RAG, \"Update 3\", retrieval_model)"
      ],
      "metadata": {
        "id": "WSd1XlACtZO4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "23d52f5c-ef7a-41ff-e862-23dc26f3fe89"
      },
      "execution_count": 48,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training RAG Update 3 Model (2020-2021)...\n",
            "\n",
            "Training RAG model for Update 3 (2020-2021)...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='732' max='944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [732/944 12:38 < 03:40, 0.96 it/s, Epoch 1.55/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.429300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='944' max='944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [944/944 16:32, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.429300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.402300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.288300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:50]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9425    0.9532    0.9478       705\n",
            "           1     0.6489    0.5980    0.6224       102\n",
            "\n",
            "    accuracy                         0.9083       807\n",
            "   macro avg     0.7957    0.7756    0.7851       807\n",
            "weighted avg     0.9054    0.9083    0.9067       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[672  33]\n",
            " [ 41  61]]\n",
            "Update 3 (2020-2021) RAG Model Test Accuracy after training: 0.9083\n",
            "Model and tokenizer saved to fine_tuned_bert_update_3_RAG\n",
            "Created fine_tuned_bert_update_3_RAG.zip\n",
            "\n",
            "Rolling Evaluation for RAG Update 3 Model:\n",
            "\n",
            "Evaluating RAG model on Update 3...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9537    0.9731    0.9633      3006\n",
            "           1     0.8851    0.8146    0.8484       766\n",
            "\n",
            "    accuracy                         0.9409      3772\n",
            "   macro avg     0.9194    0.8938    0.9058      3772\n",
            "weighted avg     0.9398    0.9409    0.9400      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2925   81]\n",
            " [ 142  624]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9537    0.9731    0.9633      3006\n",
            "           1     0.8851    0.8146    0.8484       766\n",
            "\n",
            "    accuracy                         0.9409      3772\n",
            "   macro avg     0.9194    0.8938    0.9058      3772\n",
            "weighted avg     0.9398    0.9409    0.9400      3772\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2925   81]\n",
            " [ 142  624]]\n",
            "Update 3 RAG Model Accuracy: 0.9409\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.95      0.97      0.96      3006\n",
            "        Real       0.89      0.81      0.85       766\n",
            "\n",
            "    accuracy                           0.94      3772\n",
            "   macro avg       0.92      0.89      0.91      3772\n",
            "weighted avg       0.94      0.94      0.94      3772\n",
            "\n",
            "\n",
            "Evaluating RAG model on Update 4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9170    0.8984    0.9076      1427\n",
            "           1     0.5000    0.5556    0.5263       261\n",
            "\n",
            "    accuracy                         0.8454      1688\n",
            "   macro avg     0.7085    0.7270    0.7170      1688\n",
            "weighted avg     0.8525    0.8454    0.8487      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1282  145]\n",
            " [ 116  145]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9170    0.8984    0.9076      1427\n",
            "           1     0.5000    0.5556    0.5263       261\n",
            "\n",
            "    accuracy                         0.8454      1688\n",
            "   macro avg     0.7085    0.7270    0.7170      1688\n",
            "weighted avg     0.8525    0.8454    0.8487      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1282  145]\n",
            " [ 116  145]]\n",
            "Update 4 RAG Model Accuracy: 0.8454\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.92      0.90      0.91      1427\n",
            "        Real       0.50      0.56      0.53       261\n",
            "\n",
            "    accuracy                           0.85      1688\n",
            "   macro avg       0.71      0.73      0.72      1688\n",
            "weighted avg       0.85      0.85      0.85      1688\n",
            "\n",
            "\n",
            "Evaluating RAG model on Test...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9425    0.9532    0.9478       705\n",
            "           1     0.6489    0.5980    0.6224       102\n",
            "\n",
            "    accuracy                         0.9083       807\n",
            "   macro avg     0.7957    0.7756    0.7851       807\n",
            "weighted avg     0.9054    0.9083    0.9067       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[672  33]\n",
            " [ 41  61]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9425    0.9532    0.9478       705\n",
            "           1     0.6489    0.5980    0.6224       102\n",
            "\n",
            "    accuracy                         0.9083       807\n",
            "   macro avg     0.7957    0.7756    0.7851       807\n",
            "weighted avg     0.9054    0.9083    0.9067       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[672  33]\n",
            " [ 41  61]]\n",
            "Test RAG Model Accuracy: 0.9083\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.94      0.95      0.95       705\n",
            "        Real       0.65      0.60      0.62       102\n",
            "\n",
            "    accuracy                           0.91       807\n",
            "   macro avg       0.80      0.78      0.79       807\n",
            "weighted avg       0.91      0.91      0.91       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 3': ({'eval_loss': 0.1904534548521042,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.940880169671262,\n",
              "   'eval_f1_per_class': [0.9632800922114276, 0.8484024473147519],\n",
              "   'eval_precision_per_class': [0.9537006847081839, 0.8851063829787233],\n",
              "   'eval_recall_per_class': [0.9730538922155688, 0.814621409921671],\n",
              "   'eval_confusion_matrix': [[2925, 81], [142, 624]],\n",
              "   'eval_report': {'0': {'precision': 0.9537006847081839,\n",
              "     'recall': 0.9730538922155688,\n",
              "     'f1-score': 0.9632800922114276,\n",
              "     'support': 3006.0},\n",
              "    '1': {'precision': 0.8851063829787233,\n",
              "     'recall': 0.814621409921671,\n",
              "     'f1-score': 0.8484024473147519,\n",
              "     'support': 766.0},\n",
              "    'accuracy': 0.940880169671262,\n",
              "    'macro avg': {'precision': 0.9194035338434536,\n",
              "     'recall': 0.8938376510686199,\n",
              "     'f1-score': 0.9058412697630898,\n",
              "     'support': 3772.0},\n",
              "    'weighted avg': {'precision': 0.9397708768808332,\n",
              "     'recall': 0.940880169671262,\n",
              "     'f1-score': 0.9399512809731313,\n",
              "     'support': 3772.0}},\n",
              "   'eval_runtime': 242.151,\n",
              "   'eval_samples_per_second': 15.577,\n",
              "   'eval_steps_per_second': 1.949},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.95      0.97      0.96      3006\\n        Real       0.89      0.81      0.85       766\\n\\n    accuracy                           0.94      3772\\n   macro avg       0.92      0.89      0.91      3772\\nweighted avg       0.94      0.94      0.94      3772\\n'),\n",
              " 'Update 4': ({'eval_loss': 0.4328003227710724,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.8453791469194313,\n",
              "   'eval_f1_per_class': [0.9076106194690265, 0.5263157894736842],\n",
              "   'eval_precision_per_class': [0.9170243204577968, 0.5],\n",
              "   'eval_recall_per_class': [0.8983882270497547, 0.5555555555555556],\n",
              "   'eval_confusion_matrix': [[1282, 145], [116, 145]],\n",
              "   'eval_report': {'0': {'precision': 0.9170243204577968,\n",
              "     'recall': 0.8983882270497547,\n",
              "     'f1-score': 0.9076106194690265,\n",
              "     'support': 1427.0},\n",
              "    '1': {'precision': 0.5,\n",
              "     'recall': 0.5555555555555556,\n",
              "     'f1-score': 0.5263157894736842,\n",
              "     'support': 261.0},\n",
              "    'accuracy': 0.8453791469194313,\n",
              "    'macro avg': {'precision': 0.7085121602288984,\n",
              "     'recall': 0.7269718913026552,\n",
              "     'f1-score': 0.7169632044713554,\n",
              "     'support': 1688.0},\n",
              "    'weighted avg': {'precision': 0.8525436642732679,\n",
              "     'recall': 0.8453791469194313,\n",
              "     'f1-score': 0.8486544875799363,\n",
              "     'support': 1688.0}},\n",
              "   'eval_runtime': 107.5625,\n",
              "   'eval_samples_per_second': 15.693,\n",
              "   'eval_steps_per_second': 1.962},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.92      0.90      0.91      1427\\n        Real       0.50      0.56      0.53       261\\n\\n    accuracy                           0.85      1688\\n   macro avg       0.71      0.73      0.72      1688\\nweighted avg       0.85      0.85      0.85      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.2735929489135742,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.9083023543990086,\n",
              "   'eval_f1_per_class': [0.9478138222849083, 0.6224489795918368],\n",
              "   'eval_precision_per_class': [0.9424964936886395, 0.648936170212766],\n",
              "   'eval_recall_per_class': [0.9531914893617022, 0.5980392156862745],\n",
              "   'eval_confusion_matrix': [[672, 33], [41, 61]],\n",
              "   'eval_report': {'0': {'precision': 0.9424964936886395,\n",
              "     'recall': 0.9531914893617022,\n",
              "     'f1-score': 0.9478138222849083,\n",
              "     'support': 705.0},\n",
              "    '1': {'precision': 0.648936170212766,\n",
              "     'recall': 0.5980392156862745,\n",
              "     'f1-score': 0.6224489795918368,\n",
              "     'support': 102.0},\n",
              "    'accuracy': 0.9083023543990086,\n",
              "    'macro avg': {'precision': 0.7957163319507028,\n",
              "     'recall': 0.7756153525239884,\n",
              "     'f1-score': 0.7851314009383725,\n",
              "     'support': 807.0},\n",
              "    'weighted avg': {'precision': 0.9053922148849975,\n",
              "     'recall': 0.9083023543990086,\n",
              "     'f1-score': 0.906689641424074,\n",
              "     'support': 807.0}},\n",
              "   'eval_runtime': 51.5975,\n",
              "   'eval_samples_per_second': 15.64,\n",
              "   'eval_steps_per_second': 1.957},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.94      0.95      0.95       705\\n        Real       0.65      0.60      0.62       102\\n\\n    accuracy                           0.91       807\\n   macro avg       0.80      0.78      0.79       807\\nweighted avg       0.91      0.91      0.91       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update 4 (2022)\n",
        "print(\"\\nTraining RAG Update 4 Model (2022)...\")\n",
        "model_RAG = train_rag_model(model_RAG, update4_df, retrieval_model, index_update4, headlines_update4, \"Update 4 (2022)\", test_dataset_RAG)\n",
        "save_and_zip_model(model_RAG, tokenizer, \"fine_tuned_bert_update_4_RAG\")\n",
        "print(\"\\nRolling Evaluation for RAG Update 4 Model:\")\n",
        "rolling_evaluation_RAG(model_RAG, \"Update 4\", retrieval_model)"
      ],
      "metadata": {
        "id": "vjFpOmOXtalG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba8bc4f7-3645-47df-f42a-29d706f73719"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training RAG Update 4 Model (2022)...\n",
            "\n",
            "Training RAG model for Update 4 (2022)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='422' max='422' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [422/422 07:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.333300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [101/101 00:51]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9291    0.9660    0.9471       705\n",
            "           1     0.6757    0.4902    0.5682       102\n",
            "\n",
            "    accuracy                         0.9058       807\n",
            "   macro avg     0.8024    0.7281    0.7577       807\n",
            "weighted avg     0.8970    0.9058    0.8992       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[681  24]\n",
            " [ 52  50]]\n",
            "Update 4 (2022) RAG Model Test Accuracy after training: 0.9058\n",
            "Model and tokenizer saved to fine_tuned_bert_update_4_RAG\n",
            "Created fine_tuned_bert_update_4_RAG.zip\n",
            "\n",
            "Rolling Evaluation for RAG Update 4 Model:\n",
            "\n",
            "Evaluating RAG model on Update 4...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9676    0.9832    0.9753      1427\n",
            "           1     0.8992    0.8199    0.8577       261\n",
            "\n",
            "    accuracy                         0.9579      1688\n",
            "   macro avg     0.9334    0.9016    0.9165      1688\n",
            "weighted avg     0.9570    0.9579    0.9571      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1403   24]\n",
            " [  47  214]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9676    0.9832    0.9753      1427\n",
            "           1     0.8992    0.8199    0.8577       261\n",
            "\n",
            "    accuracy                         0.9579      1688\n",
            "   macro avg     0.9334    0.9016    0.9165      1688\n",
            "weighted avg     0.9570    0.9579    0.9571      1688\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1403   24]\n",
            " [  47  214]]\n",
            "Update 4 RAG Model Accuracy: 0.9579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.97      0.98      0.98      1427\n",
            "        Real       0.90      0.82      0.86       261\n",
            "\n",
            "    accuracy                           0.96      1688\n",
            "   macro avg       0.93      0.90      0.92      1688\n",
            "weighted avg       0.96      0.96      0.96      1688\n",
            "\n",
            "\n",
            "Evaluating RAG model on Test...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9291    0.9660    0.9471       705\n",
            "           1     0.6757    0.4902    0.5682       102\n",
            "\n",
            "    accuracy                         0.9058       807\n",
            "   macro avg     0.8024    0.7281    0.7577       807\n",
            "weighted avg     0.8970    0.9058    0.8992       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[681  24]\n",
            " [ 52  50]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9291    0.9660    0.9471       705\n",
            "           1     0.6757    0.4902    0.5682       102\n",
            "\n",
            "    accuracy                         0.9058       807\n",
            "   macro avg     0.8024    0.7281    0.7577       807\n",
            "weighted avg     0.8970    0.9058    0.8992       807\n",
            "\n",
            "Confusion Matrix:\n",
            "[[681  24]\n",
            " [ 52  50]]\n",
            "Test RAG Model Accuracy: 0.9058\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.93      0.97      0.95       705\n",
            "        Real       0.68      0.49      0.57       102\n",
            "\n",
            "    accuracy                           0.91       807\n",
            "   macro avg       0.80      0.73      0.76       807\n",
            "weighted avg       0.90      0.91      0.90       807\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Update 4': ({'eval_loss': 0.13088315725326538,\n",
              "   'eval_model_preparation_time': 0.0029,\n",
              "   'eval_accuracy': 0.9579383886255924,\n",
              "   'eval_f1_per_class': [0.9753215154675009, 0.8577154308617234],\n",
              "   'eval_precision_per_class': [0.9675862068965517, 0.8991596638655462],\n",
              "   'eval_recall_per_class': [0.9831814996496145, 0.8199233716475096],\n",
              "   'eval_confusion_matrix': [[1403, 24], [47, 214]],\n",
              "   'eval_report': {'0': {'precision': 0.9675862068965517,\n",
              "     'recall': 0.9831814996496145,\n",
              "     'f1-score': 0.9753215154675009,\n",
              "     'support': 1427.0},\n",
              "    '1': {'precision': 0.8991596638655462,\n",
              "     'recall': 0.8199233716475096,\n",
              "     'f1-score': 0.8577154308617234,\n",
              "     'support': 261.0},\n",
              "    'accuracy': 0.9579383886255924,\n",
              "    'macro avg': {'precision': 0.9333729353810489,\n",
              "     'recall': 0.901552435648562,\n",
              "     'f1-score': 0.9165184731646121,\n",
              "     'support': 1688.0},\n",
              "    'weighted avg': {'precision': 0.9570060364397434,\n",
              "     'recall': 0.9579383886255924,\n",
              "     'f1-score': 0.95713716233829,\n",
              "     'support': 1688.0}},\n",
              "   'eval_runtime': 107.565,\n",
              "   'eval_samples_per_second': 15.693,\n",
              "   'eval_steps_per_second': 1.962},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.97      0.98      0.98      1427\\n        Real       0.90      0.82      0.86       261\\n\\n    accuracy                           0.96      1688\\n   macro avg       0.93      0.90      0.92      1688\\nweighted avg       0.96      0.96      0.96      1688\\n'),\n",
              " 'Test': ({'eval_loss': 0.31523633003234863,\n",
              "   'eval_model_preparation_time': 0.0028,\n",
              "   'eval_accuracy': 0.9058240396530359,\n",
              "   'eval_f1_per_class': [0.9471488178025035, 0.5681818181818182],\n",
              "   'eval_precision_per_class': [0.9290586630286494, 0.6756756756756757],\n",
              "   'eval_recall_per_class': [0.9659574468085106, 0.49019607843137253],\n",
              "   'eval_confusion_matrix': [[681, 24], [52, 50]],\n",
              "   'eval_report': {'0': {'precision': 0.9290586630286494,\n",
              "     'recall': 0.9659574468085106,\n",
              "     'f1-score': 0.9471488178025035,\n",
              "     'support': 705.0},\n",
              "    '1': {'precision': 0.6756756756756757,\n",
              "     'recall': 0.49019607843137253,\n",
              "     'f1-score': 0.5681818181818182,\n",
              "     'support': 102.0},\n",
              "    'accuracy': 0.9058240396530359,\n",
              "    'macro avg': {'precision': 0.8023671693521626,\n",
              "     'recall': 0.7280767626199416,\n",
              "     'f1-score': 0.7576653179921609,\n",
              "     'support': 807.0},\n",
              "    'weighted avg': {'precision': 0.8970325605379389,\n",
              "     'recall': 0.9058240396530359,\n",
              "     'f1-score': 0.899249643129257,\n",
              "     'support': 807.0}},\n",
              "   'eval_runtime': 51.6315,\n",
              "   'eval_samples_per_second': 15.63,\n",
              "   'eval_steps_per_second': 1.956},\n",
              "  '              precision    recall  f1-score   support\\n\\n        Fake       0.93      0.97      0.95       705\\n        Real       0.68      0.49      0.57       102\\n\\n    accuracy                           0.91       807\\n   macro avg       0.80      0.73      0.76       807\\nweighted avg       0.90      0.91      0.90       807\\n')}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}